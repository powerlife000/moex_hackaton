{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53098d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10cbadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4fecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers, initializers\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from array import *\n",
    "import os.path\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, auc, accuracy_score, roc_auc_score,f1_score,log_loss,\\\n",
    "classification_report, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sys import argv #Module for receiving parameters from the command line\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08fe6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3795366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'modules')\n",
    "from Config_module import Config\n",
    "global_config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca291a9",
   "metadata": {},
   "source": [
    "# Загрузка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6372c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_params_from_config_file = True #Загрузка параметров из файла\n",
    "load_params_from_command_line = False #Загрузка параметров из командной строки\n",
    "args = None\n",
    "\n",
    "try:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    _ = parser.add_argument('--config_file', dest='config_file', action='store_true', help='Load config from file')\n",
    "    _ = parser.add_argument('--config_path', help='Path to config file: /app/cfg.json')\n",
    "    _ = parser.add_argument('--cmd_config', dest='cmd_config', action='store_true', help='Load config from cmd line')\n",
    "    _ = parser.add_argument('--task_id')\n",
    "    _ = parser.add_argument('--data_path')\n",
    "    _ = parser.add_argument('--scaler_path')\n",
    "    _ = parser.add_argument('--neural_path')\n",
    "    _ = parser.add_argument('--new_model_flag')\n",
    "    _ = parser.add_argument('--learning_rate')\n",
    "    _ = parser.add_argument('--epochs')\n",
    "    _ = parser.add_argument('--steps_per_epoch')\n",
    "    _ = parser.add_argument('--validation_steps')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    if args.config_file:\n",
    "        load_params_from_config_file = True\n",
    "        load_params_from_command_line = False\n",
    "    \n",
    "    if args.cmd_config:\n",
    "            load_params_from_config_file = False\n",
    "            load_params_from_command_line = True\n",
    "except:\n",
    "    print(\"Ошибка парсинга параметров из командной строки\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e30d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_params_from_config_file:\n",
    "    #Если есть параметры командной строки\n",
    "    if args:\n",
    "        #Если указан путь к конфигу\n",
    "        if args.config_path:\n",
    "            with open(config_path, 'r', encoding='utf_8') as cfg:\n",
    "                temp_data=cfg.read()\n",
    "        else:\n",
    "            with open('app/configs/1D/edu_neural.json', 'r', encoding='utf_8') as cfg:\n",
    "                temp_data=cfg.read()\n",
    "\n",
    "    # parse file`\n",
    "    config = json.loads(temp_data)\n",
    "    \n",
    "    task_id = str(config['task_id'])\n",
    "    #Путь для загрузки генерируемых данных\n",
    "    data_path = config['data_path'] #Путь должен быть без чёрточки в конце\n",
    "    #Путь для сохранения скалера\n",
    "    scaler_path = config['scaler_path'] #Путь должен быть без чёрточки в конце\n",
    "    #Путь для сохранения нейронных сетей\n",
    "    neural_path = config['neural_path'] #Путь должен быть без чёрточки в конце\n",
    "    #Флаг необходимости подготовки новой модели (False - дообучение существующей)\n",
    "    new_model_flag = bool(config['new_model_flag'])\n",
    "    learning_rate = config['learning_rate']\n",
    "    epochs = config['epochs']\n",
    "    steps_per_epoch = config['steps_per_epoch']\n",
    "    validation_steps = config['validation_steps']\n",
    "    \n",
    "if load_params_from_command_line:\n",
    "    task_id = str(args.task_id)\n",
    "    data_path = str(args.data_path)\n",
    "    scaler_path = str(args.scaler_path)\n",
    "    neural_path = str(args.neural_path) \n",
    "    new_model_flag = bool(args.new_model_flag)\n",
    "    learning_rate = float(args.learning_rate) \n",
    "    epochs = int(args.epochs) \n",
    "    steps_per_epoch = int(args.steps_per_epoch) \n",
    "    validation_steps = str(args.validation_steps) \n",
    "\n",
    "Y_shift = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59496df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = 'current'# Тип нейросети в ансамбле\n",
    "period = '1d'\n",
    "\n",
    "dataset_type = 'num_logic'\n",
    "dataset_timeframe = '1d_1w'\n",
    "\n",
    "#data_type_flag = False;\n",
    "#data_type_flag = 'float16';\n",
    "data_type_flag = 'float32';\n",
    "#data_type_flag = 'float64';\n",
    "\n",
    "#Флаг необходимости масштабирования данных\n",
    "scale_flag = True\n",
    "\n",
    "\n",
    "\n",
    "#Флаг тестирования модели\n",
    "test_model_flag = False\n",
    "\n",
    "#Флаг необходимости сохранения модели\n",
    "save_model_flag = True\n",
    "\n",
    "dataset = dataset_type + '_' + dataset_timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7750e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранённый датасет отсутствует\n",
      "Импортируем данные\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './app/data/10m/num_logic_1d_1w_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     init_data_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdata_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdataset\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m'\u001b[39m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m data_type_flag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 7\u001b[0m     init_data_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     init_data_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdata_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdataset\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './app/data/10m/num_logic_1d_1w_train.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Сохранённый датасет отсутствует\")\n",
    "# Импортируем данные для обучения и тестирования\n",
    "print(\"Импортируем данные\")\n",
    "if data_type_flag == 'float16':\n",
    "    init_data_train = pd.read_csv('./'+data_path+'/'+dataset+'_train.csv', dtype = 'float16', sep = ',')\n",
    "elif data_type_flag == 'float32':\n",
    "    init_data_train = pd.read_csv('./'+data_path+'/'+dataset+'_train.csv', dtype = 'float32', sep = ',')\n",
    "else:\n",
    "    init_data_train = pd.read_csv('./'+data_path+'/'+dataset+'_train.csv', sep = ',')\n",
    "if data_type_flag == 'float16':\n",
    "    init_data_test = pd.read_csv('./'+data_path+'/'+dataset+'_test.csv', dtype = 'float16', sep = ',')\n",
    "elif data_type_flag == 'float32':\n",
    "    init_data_test = pd.read_csv('./'+data_path+'/'+dataset+'_test.csv', dtype = 'float32', sep = ',')\n",
    "else:\n",
    "    init_data_test = pd.read_csv('./app/data/'+dataset+'_test.csv', sep = ',')\n",
    "print(\"Доля NaN данных в датасете train:\", init_data_train.isna().sum() / init_data_train.shape[0]*100)\n",
    "print(\"Доля NaN данных в датасете test:\", init_data_test.isna().sum() / init_data_test.shape[0]*100)\n",
    "\n",
    "#Исключаем nan и inf\n",
    "init_data_train.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "init_data_test.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "\n",
    "# Устанавливаем размерность датасетов\n",
    "n_train = init_data_train.shape[0]\n",
    "p_train = init_data_train.shape[1]\n",
    "print(\"Число факторов: \", p_train)\n",
    "n_test = init_data_test.shape[0]\n",
    "p_test = init_data_test.shape[1]\n",
    "# Формируем данные в numpy-массив\n",
    "init_data_train = init_data_train.values\n",
    "init_data_test = init_data_test.values\n",
    "# Подготовка данных для обучения и тестирования (проверки)\n",
    "print(\"Подготавливаем обучающие, тестовые и предиктивные выборки\")\n",
    "train_start = 0\n",
    "train_end = n_train\n",
    "test_start = 0\n",
    "test_end = n_test\n",
    "data_train = init_data_train[np.arange(train_start, train_end), :]\n",
    "data_test = init_data_test[np.arange(test_start, test_end), :]\n",
    "#Выбор данных\n",
    "print(\"Выбираем данные\")\n",
    "trainX = data_train[:, 3:]\n",
    "trainY = data_train[:, 2]\n",
    "train_quotes_close = data_train[:, 1]\n",
    "testX = data_test[:, 3:]\n",
    "testY = data_test[:, 2]\n",
    "test_quotes_close = data_test[:, 1]\n",
    "# Масштабирование данных\n",
    "print(\"Масштабируем данные\")\n",
    "x_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "if scale_flag: \n",
    "    x_scaler.fit(trainX)\n",
    "    scaler_filename = './'+scaler_path+'/scaler_'+dataset+'.save'\n",
    "    joblib.dump(x_scaler, scaler_filename) \n",
    "#Изменяем размерность массива, для обеспечения возможности масштабирования Y\n",
    "trainY = trainY.reshape(-1, 1)\n",
    "testY = testY.reshape(-1, 1)\n",
    "train_quotes_close = train_quotes_close.reshape(-1, 1)\n",
    "test_quotes_close = test_quotes_close.reshape(-1, 1)\n",
    "if scale_flag:\n",
    "    #y_scaler.fit(trainY)\n",
    "    trainX = x_scaler.transform(trainX)\n",
    "    testX = x_scaler.transform(testX)\n",
    "#Изменяем размерность массива Х, для рекурентной нейросети\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверяем число анализируемых факторов\n",
    "print(\"Число анализируемых факторов\", trainX.shape[2])\n",
    "print(\"Число анализируемых данных тренировочной выборки\", trainX.shape[0])\n",
    "print(\"Число анализируемых данных тестовой выборки\", testX.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_to_png(graph):\n",
    "    buffer = io.BytesIO()\n",
    "    graph.savefig(buffer, format='png')\n",
    "    buffer.seek(0)\n",
    "    image_png = buffer.getvalue()\n",
    "    buffer.close()\n",
    "    graphic = base64.b64encode(image_png)\n",
    "    graphic = graphic.decode('utf-8')\n",
    "    graph.close()\n",
    "\n",
    "    return graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_count = trainX.shape[2]\n",
    "data_count = trainX.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cc63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train():\n",
    "    while True:\n",
    "        x = trainX\n",
    "        y = trainY\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7766db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_test():\n",
    "    while True:\n",
    "        x = testX\n",
    "        y = testY\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01bc0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfdata_generator(x_datas, y_datas, is_training, batch_size=128):\n",
    "    '''Construct a data generator using `tf.Dataset`. '''\n",
    "\n",
    "    def map_fn(x_data, y_data):\n",
    "        '''Preprocess raw data to trainable input. '''\n",
    "        x = x_data \n",
    "        y = y_data\n",
    "        return x, y\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_datas, y_datas))\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(1000)  # depends on sample size\n",
    "        dataset = dataset.map(map_fn)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31295bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = tfdata_generator(trainX, trainY,is_training=True)\n",
    "\n",
    "train_generator = data_train()\n",
    "valid_generator = data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fdb738",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9300951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверяем существование нейронной сети\n",
    "file_path = './'+neural_path+'/ansamble_'+dataset+'_v1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47c47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Тестируем нейронную сеть\n",
    "if (os.access(file_path, os.F_OK) == True) & (test_model_flag == True):\n",
    "    print(\"Тестируем нейронную сеть\")\n",
    "    #Загружаем нейронную сеть\n",
    "    print(\"Загружаем сеть\")\n",
    "    model = load_model('./'+neural_path+'/ansamble_'+dataset+'_v1.h5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518bc1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Дообучаем нейроннуюю сеть\n",
    "if (os.access(file_path, os.F_OK) == True) & (test_model_flag == False) & (new_model_flag == False):\n",
    "    print(\"Дообучаем нейронную сеть\")\n",
    "    #Загружаем нейронную сеть\n",
    "    print(\"Загружаем сеть\")\n",
    "    model = load_model('./'+neural_path+'/ansamble_'+dataset+'_v1.h5');\n",
    "    \n",
    "    #Обучаем нейронную сеть\n",
    "    print(\"Обучаем нейронную сеть\")\n",
    "    his = model.fit(\n",
    "        training_set, \n",
    "        validation_data=valid_generator, \n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch, \n",
    "        validation_steps = validation_steps, \n",
    "        callbacks=[\n",
    "            #model_checkpoint_callback,\n",
    "            #es\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if save_model_flag == True:    \n",
    "        #Сохраняем нейронную сеть\n",
    "        print(\"Сохраняем нейронную сеть\")\n",
    "        model.save('./'+neural_path+'/ansamble_'+dataset+'_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043e169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if ((os.access(file_path, os.F_OK) == False) | (new_model_flag == True)) & (test_model_flag == False) :\n",
    "    print(\"Нейронная сеть Отсутствует\")\n",
    "    # define and fit the final model\n",
    "    print(\"Формируем модель нейросети\")\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.2, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    \n",
    "    #num_logic start\n",
    "    if dataset_type == 'num_logic':\n",
    "        model.add(Dense(\n",
    "            1000,\n",
    "            activation='relu', \n",
    "            kernel_regularizer=regularizers.l2(0.001),\n",
    "            kernel_initializer='random_normal',\n",
    "            bias_initializer='zeros'\n",
    "        ))   \n",
    "        model.add(Dense(\n",
    "            500,\n",
    "            activation='relu', \n",
    "            kernel_regularizer=regularizers.l2(0.001),\n",
    "            kernel_initializer='random_normal',\n",
    "            bias_initializer='zeros'\n",
    "        ))\n",
    "        model.add(Dense(\n",
    "            units=250, \n",
    "            #125,\n",
    "            activation='tanh', \n",
    "            kernel_regularizer=regularizers.l2(0.001),\n",
    "            kernel_initializer='random_normal',\n",
    "            bias_initializer='zeros'\n",
    "        ))\n",
    "        model.add(Dense(\n",
    "            units=150, \n",
    "            #75,\n",
    "            activation='relu', \n",
    "            kernel_regularizer=regularizers.l2(0.001),\n",
    "            kernel_initializer='random_normal',\n",
    "            bias_initializer='zeros'\n",
    "        ))\n",
    "    #num_logic end\n",
    "\n",
    "    model.add(Dense(\n",
    "        3, \n",
    "        kernel_regularizer=regularizers.l2(0.01),\n",
    "        kernel_initializer='random_normal',\n",
    "        bias_initializer='zeros',\n",
    "        activation='softmax'\n",
    "    ))\n",
    "\n",
    "    opt =  keras.optimizers.Adam(clipvalue=1., clipnorm=1., learning_rate = learning_rate,amsgrad = True)\n",
    "    print(\"Компилируем нейронную сеть\")\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t   \n",
    "    \n",
    "    #Обучаем нейронную сеть\n",
    "    print(\"Обучаем нейронную сеть\")\n",
    "    his = model.fit(\n",
    "        training_set, \n",
    "        validation_data=valid_generator, \n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch, \n",
    "        validation_steps = validation_steps, \n",
    "        callbacks=[\n",
    "            #model_checkpoint_ca|llback,\n",
    "            #es\n",
    "            #tensorboard_callback\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if save_model_flag == True:    \n",
    "        #Сохраняем нейронную сеть\n",
    "        print(\"Сохраняем нейронную сеть\")\n",
    "        model.save('./'+neural_path+'/ansamble_'+dataset+'_v1.h5')\n",
    "\n",
    "    #Наблюдаем показатели точности\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Показатели точности обучения нейронной сети, loss MSE')\n",
    "    plt.plot(his.history['loss'], label='loss тренировочной выборки')\n",
    "    plt.plot(his.history['val_loss'], label='loss тестовой выборки')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    losses_results = plt_to_png(plt)\n",
    "    plt.close()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfab0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Предсказываем результат\")\n",
    "predict_testY = model.predict(testX, verbose = 1)\n",
    "predict_trainY = model.predict(trainX, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2925120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deab656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразовываем выходные сигналы тренировочной выборки\n",
    "result_predict_trainY = []\n",
    "\n",
    "for predict in predict_trainY:\n",
    "    result_predict_trainY.append(np.argmax(predict))\n",
    "        \n",
    "result_predict_trainY = np.array(result_predict_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b012b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразовываем выходные сигналы тестовой выборки\n",
    "result_predict_testY = []\n",
    "\n",
    "for predict in predict_testY:\n",
    "    result_predict_testY.append(np.argmax(predict))\n",
    "        \n",
    "result_predict_testY = np.array(result_predict_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82564f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.set_title('Сигналы тренировочной выборки')\n",
    "\n",
    "# y = trainY#Реальные значения\n",
    "# y1 = result_predict_trainY#Расчетные значения\n",
    "# y1 = y1+3\n",
    "\n",
    "# plt.plot(y, label='Размеченые данные')\n",
    "# plt.plot(y1, label='Расчётные данные нейронной сети')\n",
    "# plt.title('Тренировочная выборка')\n",
    "# plt.legend(loc=\"upper left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.set_title('Сигналы тестовой выборки')\n",
    "\n",
    "# y = testY#Реальные значения\n",
    "# y1 = result_predict_testY#Расчетные значения\n",
    "# y1 = y1+3\n",
    "\n",
    "# plt.plot(y, label='Размеченые данные')\n",
    "# plt.plot(y1, label='Расчётные данные нейронной сети')\n",
    "# plt.title('Тестовая выборка')\n",
    "# plt.legend(loc=\"upper left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e5d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b52eeae9",
   "metadata": {},
   "source": [
    "# Расчёт трендов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3520816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тренировочной выборки на основе сигналов по разметке\n",
    "last_train_signal = 2\n",
    "train_trends_origin = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(trainY.shape[0]):\n",
    "    if trainY[i] != last_train_signal and (trainY[i] == 2 or trainY[i] == 0):\n",
    "        last_train_signal = trainY[i]\n",
    "    train_trends_origin.insert(i,last_train_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тестовой выборки на основе расчётных сигналов\n",
    "last_test_signal = 2\n",
    "test_trends_origin = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(testY.shape[0]):\n",
    "    if testY[i] != last_test_signal and (testY[i] == 2 or testY[i] == 0):\n",
    "        last_test_signal = testY[i]\n",
    "    test_trends_origin.insert(i,last_test_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565436f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тренировочной выборки на основе расчётных данных\n",
    "last_train_signal = 2\n",
    "train_trends_predict = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(len(result_predict_trainY)):\n",
    "    if result_predict_trainY[i] != last_train_signal and (result_predict_trainY[i] == 2 or result_predict_trainY[i] == 0):\n",
    "        last_train_signal = result_predict_trainY[i]\n",
    "    train_trends_predict.insert(i,last_train_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тестовой выборки на основе расчётных сигналов\n",
    "last_test_signal = 2\n",
    "test_trends_predict = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(len(result_predict_testY)):\n",
    "    if result_predict_testY[i] != last_test_signal and (result_predict_testY[i] == 2 or result_predict_testY[i] == 0):\n",
    "        last_test_signal = result_predict_testY[i]\n",
    "    test_trends_predict.insert(i,last_test_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trends_origin = np.asarray(train_trends_origin).astype(int)\n",
    "test_trends_origin = np.asarray(test_trends_origin).astype(int)\n",
    "train_trends_predict = np.asarray(train_trends_predict).astype(int)\n",
    "test_trends_predict = np.asarray(test_trends_predict).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956abd7",
   "metadata": {},
   "source": [
    "# Расчёт показателей точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_score = accuracy_score(train_trends_origin, train_trends_predict)\n",
    "train_roc_auc_score = roc_auc_score(train_trends_origin, train_trends_predict)\n",
    "train_precision_score = precision_score(train_trends_origin, train_trends_predict, pos_label=2)\n",
    "train_recall_score = recall_score(train_trends_origin, train_trends_predict, pos_label=2)\n",
    "train_f1_score = f1_score(train_trends_origin, train_trends_predict, pos_label=2)\n",
    "train_log_loss = log_loss(train_trends_origin, train_trends_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выводим данные результатов анализа точности\n",
    "print(\"РЕЗУЛЬТАТЫ АНАЛИЗА ТОЧНОСТИ\");\n",
    "\n",
    "print(\"ТРЕНИРОВОЧНАЯ ВЫБОРКА\")\n",
    "print('accuracy:', accuracy_score(train_trends_origin, train_trends_predict))\n",
    "print('roc-auc:', roc_auc_score(train_trends_origin, train_trends_predict))\n",
    "print('precision:', precision_score(train_trends_origin, train_trends_predict, pos_label=2))\n",
    "print('recall:', recall_score(train_trends_origin, train_trends_predict, pos_label=2))\n",
    "print('f1:', f1_score(train_trends_origin, train_trends_predict, pos_label=2))\n",
    "print('logloss:', log_loss(train_trends_origin, train_trends_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff49902",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_score = accuracy_score(test_trends_origin, test_trends_predict)\n",
    "test_roc_auc_score = roc_auc_score(test_trends_origin, test_trends_predict)\n",
    "test_precision_score = precision_score(test_trends_origin, test_trends_predict, pos_label=2)\n",
    "test_recall_score = recall_score(test_trends_origin, test_trends_predict, pos_label=2)\n",
    "test_f1_score = f1_score(test_trends_origin, test_trends_predict, pos_label=2)\n",
    "test_log_loss = log_loss(test_trends_origin, test_trends_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6551fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ТЕСТОВАЯ ВЫБОРКА\")\n",
    "print('accuracy:', accuracy_score(test_trends_origin, test_trends_predict))\n",
    "print('roc-auc:', roc_auc_score(test_trends_origin, test_trends_predict))\n",
    "print('precision:', precision_score(test_trends_origin, test_trends_predict, pos_label=2))\n",
    "print('recall:', recall_score(test_trends_origin, test_trends_predict, pos_label=2))\n",
    "print('f1:', f1_score(test_trends_origin, test_trends_predict, pos_label=2))\n",
    "print('logloss:', log_loss(test_trends_origin, test_trends_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a7292",
   "metadata": {},
   "source": [
    "# Расчёт доходности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb20566f",
   "metadata": {},
   "source": [
    "# РАСЧЕТ ДОХОДНОСТИ ТРЕНИРОВОЧНОЙ ВЫБОРКИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"РАСЧЕТ ДОХОДНОСТИ ТРЕНИРОВОЧНОЙ ВЫБОРКИ\")\n",
    "profit_origin_arr = array('f', [])#Массив оригинальной доходности\n",
    "profit_origin_arr_shift = array('f', [])#Массив оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr = array('f', [])#Массив доходности по стандартному отклонению\n",
    "\n",
    "open_pos_flag_origin = False\n",
    "open_pos_flag_calc = False\n",
    "\n",
    "open_price_origin = 0 #Цена открытия позиции\n",
    "open_price_origin_shift = 0 #Цена открытия позиции со смещением на 1 день\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "\n",
    "profit_origin = 0 #Текущая доходность волны\n",
    "profit_origin_shift = 0 #Текущая доходность волны со смещением на 1 день\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "total_profit_origin = 1 #Общая доходность\n",
    "total_profit_origin_shift = 1 #Общая доходность со смещением на 1 день\n",
    "total_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению\n",
    "\n",
    "count_profit_origin = 0 #Номер рассчитанной доходности\n",
    "count_profit_calc_sigma = 0 #Номер рассчитанной доходности по стандартному отклонению\n",
    "\n",
    "one_profit_origin = 1 #Общая доходность при торговле одной акцией\n",
    "one_profit_origin_shift = 1 #Общая доходность со смещением на 1 день при торговле одной акцией\n",
    "one_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению при торговле одной акцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Рассчитываем доходность по уровням\n",
    "for i in range(trainX.shape[0]):\n",
    "    #Опредеяем доходность по размеченным данным\n",
    "    if trainY[i] == 2 and open_pos_flag_origin == False:\n",
    "        open_pos_flag_origin = True #Открываем позицию\n",
    "        open_price_origin = train_quotes_close[i] #Фиксируем открытие позиции\n",
    "        try:\n",
    "            open_price_origin_shift = train_quotes_close[i+1] #Фиксируем открытие позиции\n",
    "        except:\n",
    "            open_price_origin_shift = train_quotes_close[i] #Фиксируем открытие позиции\n",
    "    if trainY[i] == 0 and open_pos_flag_origin == True:\n",
    "        open_pos_flag_origin = False #Закрываем позицию\n",
    "        profit_origin = train_quotes_close[i]/open_price_origin #Фиксируем прибыль\n",
    "        one_profit_origin = one_profit_origin + (profit_origin-1) #Вычисляем доходность на одну акцию\n",
    "        try:\n",
    "            profit_origin_shift = train_quotes_close[i+1]/open_price_origin_shift #Фиксируем прибыль со смещением на 1 день\n",
    "        except:\n",
    "            profit_origin_shift = train_quotes_close[i]/open_price_origin_shift\n",
    "        total_profit_origin = total_profit_origin * profit_origin #Рассчитываем общую доходность\n",
    "        one_profit_origin_shift = one_profit_origin_shift + (profit_origin_shift-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_origin_shift = total_profit_origin_shift * profit_origin_shift #Рассчитываем общую доходность со смещением на 1 день\n",
    "        profit_origin_arr.insert(count_profit_origin, profit_origin) #Добавляем прибыль в массив\n",
    "        profit_origin_arr_shift.insert(count_profit_origin, profit_origin_shift) #Добавляем прибыль со смещением на 1 день в массив\n",
    "        count_profit_origin = count_profit_origin+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "#Обнуляем данные\n",
    "open_pos_flag_calc = False\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "#Рассчитываем доходность тренировочной выборки\n",
    "for i in range(trainX.shape[0]):\n",
    "    #Опредеяем доходность по рассчетным данным\n",
    "    if result_predict_trainY[i] == 2 and open_pos_flag_calc == False:\n",
    "        open_pos_flag_calc = True #Открываем позицию\n",
    "        open_price_calc = train_quotes_close[i] #Фиксируем открытие позиции\n",
    "    if result_predict_trainY[i] == 0 and open_pos_flag_calc == True:\n",
    "        open_pos_flag_calc = False #Закрываем позицию\n",
    "        profit_calc = train_quotes_close[i]/open_price_calc #Фиксируем прибыль\n",
    "        one_profit_calc_sigma = one_profit_calc_sigma + (profit_calc-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_calc_sigma = total_profit_calc_sigma * profit_calc #Рассчитываем общую доходность\n",
    "        profit_calc_sigma_arr.insert(count_profit_calc_sigma, profit_calc) #Добавляем прибыль в массив\n",
    "        count_profit_calc_sigma = count_profit_calc_sigma+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "\n",
    "result_profit_origin_arr = np.asarray(profit_origin_arr)\n",
    "result_profit_origin_arr_shift = np.asarray(profit_origin_arr_shift)\n",
    "result_profit_calc_sigma_arr = np.asarray(profit_calc_sigma_arr)\n",
    "\n",
    "print(\"Накопленная доходность по размеченным данным: \", total_profit_origin)\n",
    "print(\"Накопленная доходность по размеченным данным со смещением на 1 день: \", total_profit_origin_shift)\n",
    "print(\"Накопленная доходность по расчётным данным по стандартному отклонению: \", total_profit_calc_sigma)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Доходность на одну акцию размеченным данным: \", one_profit_origin)\n",
    "print(\"Доходность на одну акцию по размеченным данным со смещением на 1 день: \", one_profit_origin_shift)\n",
    "print(\"Доходность на одну акцию по расчётным данным по стандартному отклонению: \", one_profit_calc_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72048764",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Доходность трейдов тренировочной выборки')\n",
    "\n",
    "ax.hlines(1, 0, count_profit_origin)\n",
    "ax.hlines(0.5, 0, count_profit_origin)\n",
    "ax.hlines(0, 0, count_profit_calc_sigma)\n",
    "\n",
    "y_calc_profit_origin = result_profit_origin_arr\n",
    "y_calc_profit_origin_shift = result_profit_origin_arr_shift - 0.5\n",
    "y_calc_profit_sigma = result_profit_calc_sigma_arr - 1\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением на 1 день')\n",
    "plt.plot(y_calc_profit_sigma, label='Рассчётные данные данные')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd46c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_origin_arr_summ = array('f', [])#Массив накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ = array('f', [])#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ = array('f', [])#Массив накопленной доходности по стандартному отклонению\n",
    "\n",
    "profit_origin_arr_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ_show = array('f', [])#Массив смещённой накопленной доходности по стандартному отклонению\n",
    "\n",
    "last_profit_origin = 1\n",
    "last_profit_origin_shift = 1\n",
    "last_profit_calc_sigma = 1\n",
    "\n",
    "shift_origin = 0\n",
    "shift_origin_shift = -1\n",
    "shift_calc_sigma = -2\n",
    "\n",
    "for i in range(len(profit_origin_arr)):\n",
    "    profit_origin_arr_summ_show.insert(i,last_profit_origin*profit_origin_arr[i]-shift_origin)\n",
    "    profit_origin_arr_summ.insert(i,last_profit_origin*profit_origin_arr[i])\n",
    "    last_profit_origin = last_profit_origin*profit_origin_arr[i]\n",
    "\t\n",
    "for i in range(len(profit_origin_arr_shift)):\n",
    "    profit_origin_arr_shift_summ_show.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i]-shift_origin_shift)\n",
    "    profit_origin_arr_shift_summ.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i])\n",
    "    last_profit_origin_shift = last_profit_origin_shift*profit_origin_arr_shift[i]\n",
    "\n",
    "for i in range(len(profit_calc_sigma_arr)):\n",
    "    profit_calc_sigma_arr_summ_show.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i]-shift_calc_sigma)\n",
    "    profit_calc_sigma_arr_summ.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i])\n",
    "    last_profit_calc_sigma = last_profit_calc_sigma*profit_calc_sigma_arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Накопленная доходность тренировочной выборки')\n",
    "\n",
    "y_calc_profit_origin = profit_origin_arr_summ_show\n",
    "y_calc_profit_origin_shift = profit_origin_arr_shift_summ_show\n",
    "y_calc_profit_sigma = profit_calc_sigma_arr_summ_show\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением')\n",
    "plt.plot(y_calc_profit_sigma, label='Рассчётные данные')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_profit_origin_arr = profit_origin_arr#Массив оригинальной доходности\n",
    "train_profit_origin_arr_shift = profit_origin_arr_shift#Массив оригинальной доходности со смещением на 1 день\n",
    "train_profit_calc_sigma_arr = profit_calc_sigma_arr#Массив доходности по стандартному отклонению\n",
    "\n",
    "train_profit_origin_arr_summ = profit_origin_arr_summ#Массив накопленной оригинальной доходности\n",
    "train_profit_origin_arr_shift_summ = profit_origin_arr_shift_summ#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "train_profit_calc_sigma_arr_summ = profit_calc_sigma_arr_summ#Массив накопленной доходности по стандартному отклонению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab4966",
   "metadata": {},
   "source": [
    "# Тестовая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31cbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t#РАСЧЕТ ДОХОДНОСТИ ТЕСТОВОЙ ВЫБОРКИ\n",
    "print(\"\")\n",
    "print(\"РАСЧЕТ ДОХОДНОСТИ ТЕСТОВОЙ ВЫБОРКИ\")\n",
    "profit_origin_arr = array('f', [])#Массив оригинальной доходности\n",
    "profit_origin_arr_shift = array('f', [])#Массив оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr = array('f', [])#Массив доходности по стандартному отклонению\n",
    "\n",
    "open_pos_flag_origin = False\n",
    "open_pos_flag_calc = False\n",
    "\n",
    "open_price_origin = 0 #Цена открытия позиции\n",
    "open_price_origin_shift = 0 #Цена открытия позиции со смещением на 1 день\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "\n",
    "profit_origin = 0 #Текущая доходность волны\n",
    "profit_origin_shift = 0 #Текущая доходность волны со смещением на 1 день\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "total_profit_origin = 1 #Общая доходность\n",
    "total_profit_origin_shift = 1 #Общая доходность со смещением на 1 день\n",
    "total_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению\n",
    "\n",
    "count_profit_origin = 0 #Номер рассчитанной доходности\n",
    "count_profit_calc_sigma = 0 #Номер рассчитанной доходности по стандартному отклонению\n",
    "\n",
    "one_profit_origin = 1 #Общая доходность при торговле одной акцией\n",
    "one_profit_origin_shift = 1 #Общая доходность со смещением на 1 день при торговле одной акцией\n",
    "one_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению при торговле одной акцией\n",
    "\n",
    "#Рассчитываем доходность по уровням\n",
    "for i in range(testX.shape[0]):\n",
    "    #Опредеяем доходность по размеченным данным\n",
    "    if testY[i] == 2 and open_pos_flag_origin == False:\n",
    "        open_pos_flag_origin = True #Открываем позицию\n",
    "        open_price_origin = test_quotes_close[i] #Фиксируем открытие позиции\n",
    "        open_price_origin_shift = test_quotes_close[i+1] #Фиксируем открытие позиции\n",
    "    if testY[i] == 0 and open_pos_flag_origin == True:\n",
    "        open_pos_flag_origin = False #Закрываем позицию\n",
    "        profit_origin = test_quotes_close[i]/open_price_origin #Фиксируем прибыль\n",
    "        one_profit_origin = one_profit_origin + (profit_origin-1) #Вычисляем доходность на одну акцию\n",
    "        profit_origin_shift = test_quotes_close[i+1]/open_price_origin_shift #Фиксируем прибыль со смещением на 1 день\n",
    "        total_profit_origin = total_profit_origin * profit_origin #Рассчитываем общую доходность\n",
    "        one_profit_origin_shift = one_profit_origin_shift + (profit_origin_shift-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_origin_shift = total_profit_origin_shift * profit_origin_shift #Рассчитываем общую доходность со смещением на 1 день\n",
    "        profit_origin_arr.insert(count_profit_origin, profit_origin) #Добавляем прибыль в массив\n",
    "        profit_origin_arr_shift.insert(count_profit_origin, profit_origin_shift) #Добавляем прибыль со смещением на 1 день в массив\n",
    "        count_profit_origin = count_profit_origin+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "#Обнуляем данные\n",
    "open_pos_flag_calc = False\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "#Рассчитываем доходность тренировочной выборки\n",
    "for i in range(testX.shape[0]):\n",
    "    #Опредеяем доходность по рассчетным данным\n",
    "    if result_predict_testY[i] == 2 and open_pos_flag_calc == False:\n",
    "        open_pos_flag_calc = True #Открываем позицию\n",
    "        open_price_calc = test_quotes_close[i] #Фиксируем открытие позиции\n",
    "    if result_predict_testY[i] == 0 and open_pos_flag_calc == True:\n",
    "        open_pos_flag_calc = False #Закрываем позицию\n",
    "        profit_calc = test_quotes_close[i]/open_price_calc #Фиксируем прибыль\n",
    "        one_profit_calc_sigma = one_profit_calc_sigma + (profit_calc-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_calc_sigma = total_profit_calc_sigma * profit_calc #Рассчитываем общую доходность\n",
    "        profit_calc_sigma_arr.insert(count_profit_calc_sigma, profit_calc) #Добавляем прибыль в массив\n",
    "        count_profit_calc_sigma = count_profit_calc_sigma+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "\n",
    "result_profit_origin_arr = np.asarray(profit_origin_arr)\n",
    "result_profit_origin_arr_shift = np.asarray(profit_origin_arr_shift)\n",
    "result_profit_calc_sigma_arr = np.asarray(profit_calc_sigma_arr)\n",
    "\n",
    "print(\"Накопленная доходность по размеченным данным: \", total_profit_origin)\n",
    "print(\"Накопленная доходность по размеченным данным со смещением на 1 день: \", total_profit_origin_shift)\n",
    "print(\"Накопленная доходность по расчётным данным: \", total_profit_calc_sigma)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Доходность на одну акцию размеченным данным: \", one_profit_origin)\n",
    "print(\"Доходность на одну акцию по размеченным данным со смещением на 1 день: \", one_profit_origin_shift)\n",
    "print(\"Доходность на одну акцию по расчётным данным: \", one_profit_calc_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Доходность трейдов тестовой выборки')\n",
    "\n",
    "ax.hlines(1, 0, count_profit_origin)\n",
    "ax.hlines(0.5, 0, count_profit_origin)\n",
    "ax.hlines(0, 0, count_profit_calc_sigma)\n",
    "\n",
    "y_calc_profit_origin = result_profit_origin_arr\n",
    "y_calc_profit_origin_shift = result_profit_origin_arr_shift - 0.5\n",
    "y_calc_profit_sigma = result_profit_calc_sigma_arr - 1\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением на 1 день')\n",
    "plt.plot(y_calc_profit_sigma, label='Расчётные данные')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_origin_arr_summ = array('f', [])#Массив накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ = array('f', [])#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ = array('f', [])#Массив накопленной доходности по стандартному отклонению\n",
    "\n",
    "profit_origin_arr_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ_show = array('f', [])#Массив смещённой накопленной доходности по стандартному отклонению\n",
    "\n",
    "last_profit_origin = 1\n",
    "last_profit_origin_shift = 1\n",
    "last_profit_calc_sigma = 1\n",
    "\n",
    "shift_origin = 0\n",
    "shift_origin_shift = -1\n",
    "shift_calc_sigma = -2\n",
    "\n",
    "for i in range(len(profit_origin_arr)):\n",
    "    profit_origin_arr_summ_show.insert(i,last_profit_origin*profit_origin_arr[i]-shift_origin)\n",
    "    profit_origin_arr_summ.insert(i,last_profit_origin*profit_origin_arr[i])\n",
    "    last_profit_origin = last_profit_origin*profit_origin_arr[i]\n",
    "\t\n",
    "for i in range(len(profit_origin_arr_shift)):\n",
    "    profit_origin_arr_shift_summ_show.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i]-shift_origin_shift)\n",
    "    profit_origin_arr_shift_summ.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i])\n",
    "    last_profit_origin_shift = last_profit_origin_shift*profit_origin_arr_shift[i]\n",
    "\n",
    "for i in range(len(profit_calc_sigma_arr)):\n",
    "    profit_calc_sigma_arr_summ_show.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i]-shift_calc_sigma)\n",
    "    profit_calc_sigma_arr_summ.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i])\n",
    "    last_profit_calc_sigma = last_profit_calc_sigma*profit_calc_sigma_arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Накопленная доходность тестовой выборки')\n",
    "\n",
    "y_calc_profit_origin = profit_origin_arr_summ_show\n",
    "y_calc_profit_origin_shift = profit_origin_arr_shift_summ_show\n",
    "y_calc_profit_sigma = profit_calc_sigma_arr_summ_show\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением на 1 день')\n",
    "plt.plot(y_calc_profit_sigma, label='Рассчётные сигналы')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "test_profit_origin_arr = profit_origin_arr#Массив оригинальной доходности\n",
    "test_profit_origin_arr_shift = profit_origin_arr_shift#Массив оригинальной доходности со смещением на 1 день\n",
    "test_profit_calc_sigma_arr = profit_calc_sigma_arr#Массив доходности по стандартному отклонению\n",
    "\n",
    "test_profit_origin_arr_summ = profit_origin_arr_summ#Массив накопленной оригинальной доходности\n",
    "test_profit_origin_arr_shift_summ = profit_origin_arr_shift_summ#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "test_profit_calc_sigma_arr_summ = profit_calc_sigma_arr_summ#Массив накопленной доходности по стандартному отклонению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457e9b12",
   "metadata": {},
   "source": [
    "# РАСЧЕТ РИСКОВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"РАСЧЕТ РИСКОВ\")\n",
    "\n",
    "#ТРЕНИРОВОЧНАЯ ВЫБОРКА\n",
    "print(\"ТРЕНИРОВОЧНАЯ ВЫБОРКА\")\n",
    "\n",
    "#Дисперсия портфеля\n",
    "\n",
    "#Дисперсия по размеченным данным\n",
    "print(\"Дисперсия по размеченным данным: \", np.var(train_profit_origin_arr_summ))\n",
    "\n",
    "#Дисперсия по размеченным данным со смещением\n",
    "print(\"Дисперсия по размеченным данным со смещением: \", np.var(train_profit_origin_arr_shift_summ))\n",
    "\n",
    "#Дисперсия по расчётным данным\n",
    "print(\"Дисперсия по расчётным данным: \", np.var(train_profit_calc_sigma_arr_summ))\n",
    "\n",
    "#Коэффициент Шарпа\n",
    "R = 5#Безрисковая ставка\n",
    "#Коэффициент Шарпа по размеченным данным\n",
    "print(\"Коэффициент Шарпа по размеченным данным: \", ((train_profit_origin_arr_summ[len(train_profit_origin_arr_summ)-1]-1)*100-R)/sqrt(np.var(train_profit_origin_arr_summ)))\n",
    "\n",
    "#Коэффициент Шарпа по размеченным данным со смещением\n",
    "print(\"Коэффициент Шарпа по размеченным данным со смещением: \", ((train_profit_origin_arr_shift_summ[len(train_profit_origin_arr_shift_summ)-1]-1)*100-R)/sqrt(np.var(train_profit_origin_arr_shift_summ)))\n",
    "\n",
    "sharp = 0\t\t\n",
    "if train_profit_calc_sigma_arr_summ != 0:\n",
    "    sharp = ((train_profit_calc_sigma_arr_summ[len(train_profit_calc_sigma_arr_summ)-1]-1)*100-R)/sqrt(np.var(train_profit_calc_sigma_arr_summ))\n",
    "\n",
    "#Коэффициент Шарпа по расчётным данным\n",
    "print(\"Коэффициент Шарпа по расчётным данным: \", sharp)\n",
    "\n",
    "#ТЕСТОВАЯ ВЫБОРКА\n",
    "print(\"ТЕСТОВАЯ ВЫБОРКА\")\n",
    "#Дисперсия портфеля\n",
    "\n",
    "#Дисперсия по размеченным данным\n",
    "print(\"Дисперсия по размеченным данным: \", np.var(test_profit_origin_arr_summ))\n",
    "\n",
    "#Дисперсия по размеченным данным со смещением\n",
    "print(\"Дисперсия по размеченным данным со смещением: \", np.var(test_profit_origin_arr_shift_summ))\n",
    "\n",
    "#Дисперсия по расчётным данным\n",
    "print(\"Дисперсия по расчётным данным: \", np.var(test_profit_calc_sigma_arr_summ))\n",
    "\n",
    "#Коэффициент Шарпа\n",
    "R = 5#Безрисковая ставка\n",
    "\t\t#Коэффициент Шарпа по размеченным данным\n",
    "sharp = 0\t\t\n",
    "if sqrt(np.var(test_profit_origin_arr_summ)) != 0:\n",
    "    sharp = ((test_profit_origin_arr_summ[len(test_profit_origin_arr_summ)-1]-1)*100-R)/sqrt(np.var(test_profit_origin_arr_summ))\n",
    "print(\"Коэффициент Шарпа по размеченным данным: \", sharp)\n",
    "\n",
    "#Коэффициент Шарпа по размеченным данным со смещением\n",
    "sharp = 0\t\t\n",
    "if sqrt(np.var(test_profit_origin_arr_shift_summ)) != 0:\n",
    "    sharp = ((test_profit_origin_arr_shift_summ[len(test_profit_origin_arr_shift_summ)-1]-1)*100-R)/sqrt(np.var(test_profit_origin_arr_shift_summ))\n",
    "\n",
    "#Коэффициент Шарпа по расчётным данным\n",
    "print(\"Коэффициент Шарпа по размеченным данным со смещением: \", sharp)\n",
    "\n",
    "sharp = 0\n",
    "if sqrt(np.var(test_profit_calc_sigma_arr_summ)) != 0:\n",
    "    sharp = ((test_profit_calc_sigma_arr_summ[len(test_profit_calc_sigma_arr_summ)-1]-1)*100-R)/sqrt(np.var(test_profit_calc_sigma_arr_summ))\n",
    "\n",
    "#Коэффициент Шарпа по расчётным данным\n",
    "print(\"Коэффициент Шарпа по расчётным данным: \", sharp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf22ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a301f62",
   "metadata": {},
   "source": [
    "# Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c071052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Соединение с БД\n",
    "def connect():\n",
    "    return psycopg2.connect(\n",
    "        host=global_config.db_host,\n",
    "        database=global_config.db_database,\n",
    "        user=global_config.db_user,\n",
    "        password=global_config.db_password\n",
    "    )\n",
    "conn = connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conn.closed == 1:\n",
    "    conn = connect()\n",
    "#Проверяем наличие записи\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM public.edu_neural_results WHERE task_id  = %s;\", (task_id,))\n",
    "results = cur.fetchall()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee32321",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conn.closed == 1:\n",
    "    conn = connect()\n",
    "cur = conn.cursor()\n",
    "try:\n",
    "    if len(results) == 0:\n",
    "        print(\"Записываем результаты\")\n",
    "        #Записи о результатах в БД нет, записываем новый результат\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO public.edu_neural_results \n",
    "            (\n",
    "                task_id, \n",
    "                losses_results, \n",
    "                train_accuracy_score, \n",
    "                train_roc_auc_score, \n",
    "                train_precision_score, \n",
    "                train_recall_score, \n",
    "                train_f1_score, \n",
    "                train_log_loss,\n",
    "                test_accuracy_score, \n",
    "                test_roc_auc_score, \n",
    "                test_precision_score, \n",
    "                test_recall_score, \n",
    "                test_f1_score, \n",
    "                test_log_loss\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "            \"\"\",\n",
    "            (\n",
    "                task_id, \n",
    "                losses_results, \n",
    "                train_accuracy_score, \n",
    "                train_roc_auc_score, \n",
    "                train_precision_score, \n",
    "                train_recall_score, \n",
    "                train_f1_score, \n",
    "                train_log_loss,\n",
    "                test_accuracy_score, \n",
    "                test_roc_auc_score, \n",
    "                test_precision_score, \n",
    "                test_recall_score, \n",
    "                test_f1_score, \n",
    "                test_log_loss\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        #Обновляем запись\n",
    "        print(\"Обновляем результаты\")\n",
    "        sql = \"\"\" UPDATE public.edu_neural_results\n",
    "                    SET \n",
    "                    losses_results = %s, \n",
    "                    train_accuracy_score = %s, \n",
    "                    train_roc_auc_score = %s, \n",
    "                    train_precision_score = %s, \n",
    "                    train_recall_score = %s, \n",
    "                    train_f1_score = %s, \n",
    "                    train_log_loss = %s,\n",
    "                    test_accuracy_score = %s, \n",
    "                    test_roc_auc_score = %s, \n",
    "                    test_precision_score = %s, \n",
    "                    test_recall_score = %s, \n",
    "                    test_f1_score = %s, \n",
    "                    test_log_loss = %s\n",
    "                    WHERE task_id = %s\"\"\"\n",
    "        cur.execute(sql, (\n",
    "                losses_results, \n",
    "                train_accuracy_score, \n",
    "                train_roc_auc_score, \n",
    "                train_precision_score, \n",
    "                train_recall_score, \n",
    "                train_f1_score, \n",
    "                train_log_loss,\n",
    "                test_accuracy_score, \n",
    "                test_roc_auc_score, \n",
    "                test_precision_score, \n",
    "                test_recall_score, \n",
    "                test_f1_score, \n",
    "                test_log_loss,\n",
    "                task_id\n",
    "            ))\n",
    "except Exception as e:\n",
    "    print(\"Ошибка записи результатов в БД: \", e)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47378885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обновляем данные по задаче\n",
    "if conn.closed == 1:\n",
    "    conn = connect()\n",
    "cur = conn.cursor()\n",
    "\n",
    "sql = \"\"\" UPDATE data_markup_results\n",
    "            SET task_status = %s\n",
    "            WHERE id = %s\"\"\"\n",
    "try:\n",
    "    cur.execute(sql, ('done', task_id))\n",
    "except Exception as e:\n",
    "    print(\"Ошибка записи информации о закрытии задачи в БД: \", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
