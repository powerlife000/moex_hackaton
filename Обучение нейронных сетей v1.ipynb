{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53098d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2c57bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b4fecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers, initializers\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from array import *\n",
    "import os.path\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, auc, accuracy_score, roc_auc_score,f1_score,log_loss,\\\n",
    "classification_report, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sys import argv #Module for receiving parameters from the command line\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08fe6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "861845c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'modules')\n",
    "from Config_module import Config\n",
    "global_config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d7d43",
   "metadata": {},
   "source": [
    "# Загрузка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8002fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_params_from_config_file = True #Загрузка параметров из файла\n",
    "load_params_from_command_line = False #Загрузка параметров из командной строки\n",
    "args = None\n",
    "\n",
    "try:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    _ = parser.add_argument('--config_file', dest='config_file', action='store_true', help='Load config from file')\n",
    "    _ = parser.add_argument('--config_path', help='Path to config file: /app/cfg.json')\n",
    "    _ = parser.add_argument('--cmd_config', dest='cmd_config', action='store_true', help='Load config from cmd line')\n",
    "    _ = parser.add_argument('--task_id')\n",
    "    _ = parser.add_argument('--data_path')\n",
    "    _ = parser.add_argument('--scaler_path')\n",
    "    _ = parser.add_argument('--neural_path')\n",
    "    _ = parser.add_argument('--new_model_flag')\n",
    "    _ = parser.add_argument('--learning_rate')\n",
    "    _ = parser.add_argument('--epochs')\n",
    "    _ = parser.add_argument('--steps_per_epoch')\n",
    "    _ = parser.add_argument('--validation_steps')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    if args.config_file:\n",
    "        load_params_from_config_file = True\n",
    "        load_params_from_command_line = False\n",
    "    \n",
    "    if args.cmd_config:\n",
    "            load_params_from_config_file = False\n",
    "            load_params_from_command_line = True\n",
    "except:\n",
    "    print(\"Ошибка парсинга параметров из командной строки\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e14d1a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_params_from_config_file:\n",
    "    #Если есть параметры командной строки\n",
    "    if args:\n",
    "        #Если указан путь к конфигу\n",
    "        if args.config_path:\n",
    "            with open(config_path, 'r', encoding='utf_8') as cfg:\n",
    "                temp_data=cfg.read()\n",
    "        else:\n",
    "            with open('app/configs/10m/edu_neural.json', 'r', encoding='utf_8') as cfg:\n",
    "                temp_data=cfg.read()\n",
    "\n",
    "    # parse file`\n",
    "    config = json.loads(temp_data)\n",
    "    \n",
    "    task_id = str(config['task_id'])\n",
    "    #Путь для загрузки генерируемых данных\n",
    "    data_path = config['data_path'] #Путь должен быть без чёрточки в конце\n",
    "    #Путь для сохранения скалера\n",
    "    scaler_path = config['scaler_path'] #Путь должен быть без чёрточки в конце\n",
    "    #Путь для сохранения нейронных сетей\n",
    "    neural_path = config['neural_path'] #Путь должен быть без чёрточки в конце\n",
    "    #Флаг необходимости подготовки новой модели (False - дообучение существующей)\n",
    "    new_model_flag = bool(config['new_model_flag'])\n",
    "    learning_rate = config['learning_rate']\n",
    "    epochs = config['epochs']\n",
    "    steps_per_epoch = config['steps_per_epoch']\n",
    "    validation_steps = config['validation_steps']\n",
    "    \n",
    "if load_params_from_command_line:\n",
    "    task_id = str(args.task_id)\n",
    "    data_path = str(args.data_path)\n",
    "    scaler_path = str(args.scaler_path)\n",
    "    neural_path = str(args.neural_path) \n",
    "    new_model_flag = bool(args.new_model_flag)\n",
    "    learning_rate = float(args.learning_rate) \n",
    "    epochs = int(args.epochs) \n",
    "    steps_per_epoch = int(args.steps_per_epoch) \n",
    "    validation_steps = str(args.validation_steps) \n",
    "\n",
    "Y_shift = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "59496df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = 'current'# Тип нейросети в ансамбле\n",
    "period = '1d'\n",
    "\n",
    "dataset_type = 'num_logic'\n",
    "dataset_timeframe = '1d_1w'\n",
    "\n",
    "#data_type_flag = False;\n",
    "#data_type_flag = 'float16';\n",
    "data_type_flag = 'float32';\n",
    "#data_type_flag = 'float64';\n",
    "\n",
    "#Флаг необходимости масштабирования данных\n",
    "scale_flag = True\n",
    "\n",
    "\n",
    "\n",
    "#Флаг тестирования модели\n",
    "test_model_flag = False\n",
    "\n",
    "#Флаг необходимости сохранения модели\n",
    "save_model_flag = True\n",
    "\n",
    "dataset = dataset_type + '_' + dataset_timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7750e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранённый датасет отсутствует\n",
      "Импортируем данные\n",
      "Доля NaN данных в датасете train: Datetime     0.0\n",
      "Close        0.0\n",
      "Y            0.0\n",
      "Open:5m      0.0\n",
      "High:5m      0.0\n",
      "            ... \n",
      "gap_14:5m    0.0\n",
      "gap_16:5m    0.0\n",
      "gap_18:5m    0.0\n",
      "gap_20:5m    0.0\n",
      "gap_40:5m    0.0\n",
      "Length: 2662, dtype: float64\n",
      "Доля NaN данных в датасете test: Datetime     0.0\n",
      "Close        0.0\n",
      "Y            0.0\n",
      "Open:5m      0.0\n",
      "High:5m      0.0\n",
      "            ... \n",
      "gap_14:5m    0.0\n",
      "gap_16:5m    0.0\n",
      "gap_18:5m    0.0\n",
      "gap_20:5m    0.0\n",
      "gap_40:5m    0.0\n",
      "Length: 2662, dtype: float64\n",
      "Число факторов:  2662\n",
      "Подготавливаем обучающие, тестовые и предиктивные выборки\n",
      "Выбираем данные\n",
      "Масштабируем данные\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Сохранённый датасет отсутствует\")\n",
    "# Импортируем данные для обучения и тестирования\n",
    "print(\"Импортируем данные\")\n",
    "if data_type_flag == 'float16':\n",
    "    init_data_train = pd.read_csv('./'+data_path+'/'+dataset+'_train.csv', dtype = 'float16', sep = ',')\n",
    "elif data_type_flag == 'float32':\n",
    "    init_data_train = pd.read_csv('./'+data_path+'/'+dataset+'_train.csv', dtype = 'float32', sep = ',')\n",
    "else:\n",
    "    init_data_train = pd.read_csv('./'+data_path+'/'+dataset+'_train.csv', sep = ',')\n",
    "if data_type_flag == 'float16':\n",
    "    init_data_test = pd.read_csv('./'+data_path+'/'+dataset+'_test.csv', dtype = 'float16', sep = ',')\n",
    "elif data_type_flag == 'float32':\n",
    "    init_data_test = pd.read_csv('./'+data_path+'/'+dataset+'_test.csv', dtype = 'float32', sep = ',')\n",
    "else:\n",
    "    init_data_test = pd.read_csv('./app/data/'+dataset+'_test.csv', sep = ',')\n",
    "print(\"Доля NaN данных в датасете train:\", init_data_train.isna().sum() / init_data_train.shape[0]*100)\n",
    "print(\"Доля NaN данных в датасете test:\", init_data_test.isna().sum() / init_data_test.shape[0]*100)\n",
    "\n",
    "#Исключаем nan и inf\n",
    "init_data_train.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "init_data_test.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "\n",
    "# Устанавливаем размерность датасетов\n",
    "n_train = init_data_train.shape[0]\n",
    "p_train = init_data_train.shape[1]\n",
    "print(\"Число факторов: \", p_train)\n",
    "n_test = init_data_test.shape[0]\n",
    "p_test = init_data_test.shape[1]\n",
    "# Формируем данные в numpy-массив\n",
    "init_data_train = init_data_train.values\n",
    "init_data_test = init_data_test.values\n",
    "# Подготовка данных для обучения и тестирования (проверки)\n",
    "print(\"Подготавливаем обучающие, тестовые и предиктивные выборки\")\n",
    "train_start = 0\n",
    "train_end = n_train\n",
    "test_start = 0\n",
    "test_end = n_test\n",
    "data_train = init_data_train[np.arange(train_start, train_end), :]\n",
    "data_test = init_data_test[np.arange(test_start, test_end), :]\n",
    "#Выбор данных\n",
    "print(\"Выбираем данные\")\n",
    "trainX = data_train[:, 3:]\n",
    "trainY = data_train[:, 2]\n",
    "train_quotes_close = data_train[:, 1]\n",
    "testX = data_test[:, 3:]\n",
    "testY = data_test[:, 2]\n",
    "test_quotes_close = data_test[:, 1]\n",
    "# Масштабирование данных\n",
    "print(\"Масштабируем данные\")\n",
    "x_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "if scale_flag: \n",
    "    x_scaler.fit(trainX)\n",
    "    scaler_filename = './'+scaler_path+'/scaler_'+dataset+'.save'\n",
    "    joblib.dump(x_scaler, scaler_filename) \n",
    "#Изменяем размерность массива, для обеспечения возможности масштабирования Y\n",
    "trainY = trainY.reshape(-1, 1)\n",
    "testY = testY.reshape(-1, 1)\n",
    "train_quotes_close = train_quotes_close.reshape(-1, 1)\n",
    "test_quotes_close = test_quotes_close.reshape(-1, 1)\n",
    "if scale_flag:\n",
    "    #y_scaler.fit(trainY)\n",
    "    trainX = x_scaler.transform(trainX)\n",
    "    testX = x_scaler.transform(testX)\n",
    "#Изменяем размерность массива Х, для рекурентной нейросети\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f849b9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число анализируемых факторов 2659\n",
      "Число анализируемых данных тренировочной выборки 147817\n",
      "Число анализируемых данных тестовой выборки 16426\n"
     ]
    }
   ],
   "source": [
    "#Проверяем число анализируемых факторов\n",
    "print(\"Число анализируемых факторов\", trainX.shape[2])\n",
    "print(\"Число анализируемых данных тренировочной выборки\", trainX.shape[0])\n",
    "print(\"Число анализируемых данных тестовой выборки\", testX.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08da91ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_to_png(graph):\n",
    "    buffer = io.BytesIO()\n",
    "    graph.savefig(buffer, format='png')\n",
    "    buffer.seek(0)\n",
    "    image_png = buffer.getvalue()\n",
    "    buffer.close()\n",
    "    graphic = base64.b64encode(image_png)\n",
    "    graphic = graphic.decode('utf-8')\n",
    "    graph.close()\n",
    "\n",
    "    return graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73e16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_count = trainX.shape[2]\n",
    "data_count = trainX.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b3cc63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train():\n",
    "    while True:\n",
    "        x = trainX\n",
    "        y = trainY\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7766db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_test():\n",
    "    while True:\n",
    "        x = testX\n",
    "        y = testY\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c01bc0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfdata_generator(x_datas, y_datas, is_training, batch_size=128):\n",
    "    '''Construct a data generator using `tf.Dataset`. '''\n",
    "\n",
    "    def map_fn(x_data, y_data):\n",
    "        '''Preprocess raw data to trainable input. '''\n",
    "        x = x_data \n",
    "        y = y_data\n",
    "        return x, y\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_datas, y_datas))\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(1000)  # depends on sample size\n",
    "        dataset = dataset.map(map_fn)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31295bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = tfdata_generator(trainX, trainY,is_training=True)\n",
    "\n",
    "train_generator = data_train()\n",
    "valid_generator = data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a9f862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "666a397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3fdb738",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9300951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверяем существование нейронной сети\n",
    "file_path = './'+neural_path+'/ansamble_'+dataset+'_v1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b47c47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Тестируем нейронную сеть\n",
    "if (os.access(file_path, os.F_OK) == True) & (test_model_flag == True):\n",
    "    print(\"Тестируем нейронную сеть\")\n",
    "    #Загружаем нейронную сеть\n",
    "    print(\"Загружаем сеть\")\n",
    "    model = load_model('./'+neural_path+'/ansamble_'+dataset+'_v1.h5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "518bc1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Дообучаем нейроннуюю сеть\n",
    "if (os.access(file_path, os.F_OK) == True) & (test_model_flag == False) & (new_model_flag == False):\n",
    "    print(\"Дообучаем нейронную сеть\")\n",
    "    #Загружаем нейронную сеть\n",
    "    print(\"Загружаем сеть\")\n",
    "    model = load_model('./'+neural_path+'/ansamble_'+dataset+'_v1.h5');\n",
    "    \n",
    "    #Обучаем нейронную сеть\n",
    "    print(\"Обучаем нейронную сеть\")\n",
    "    his = model.fit(\n",
    "        training_set, \n",
    "        validation_data=valid_generator, \n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch, \n",
    "        validation_steps = validation_steps, \n",
    "        callbacks=[\n",
    "            #model_checkpoint_callback,\n",
    "            #es\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if save_model_flag == True:    \n",
    "        #Сохраняем нейронную сеть\n",
    "        print(\"Сохраняем нейронную сеть\")\n",
    "        model.save('./'+neural_path+'/ansamble_'+dataset+'_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d043e169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нейронная сеть Отсутствует\n",
      "Формируем модель нейросети\n",
      "Компилируем нейронную сеть\n",
      "Обучаем нейронную сеть\n",
      "Epoch 1/350\n",
      "128/128 [==============================] - 114s 892ms/step - loss: 9.3482 - accuracy: 0.3578 - val_loss: 9.2497 - val_accuracy: 0.3540\n",
      "Epoch 2/350\n",
      "128/128 [==============================] - 117s 922ms/step - loss: 9.1895 - accuracy: 0.4455 - val_loss: 9.1319 - val_accuracy: 0.3512\n",
      "Epoch 3/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 9.0610 - accuracy: 0.4341 - val_loss: 8.8818 - val_accuracy: 0.6208\n",
      "Epoch 4/350\n",
      "128/128 [==============================] - 37s 290ms/step - loss: 8.1362 - accuracy: 0.9672 - val_loss: 9.2449 - val_accuracy: 0.6197\n",
      "Epoch 5/350\n",
      "128/128 [==============================] - 37s 290ms/step - loss: 8.4749 - accuracy: 0.7860 - val_loss: 8.7965 - val_accuracy: 0.6197\n",
      "Epoch 6/350\n",
      "128/128 [==============================] - 37s 289ms/step - loss: 8.6106 - accuracy: 0.5051 - val_loss: 8.6074 - val_accuracy: 0.4585\n",
      "Epoch 7/350\n",
      "128/128 [==============================] - 37s 290ms/step - loss: 8.5803 - accuracy: 0.3926 - val_loss: 8.4464 - val_accuracy: 0.4697\n",
      "Epoch 8/350\n",
      "128/128 [==============================] - 37s 291ms/step - loss: 8.4464 - accuracy: 0.4095 - val_loss: 8.2947 - val_accuracy: 0.4794\n",
      "Epoch 9/350\n",
      "128/128 [==============================] - 37s 291ms/step - loss: 8.0185 - accuracy: 0.6830 - val_loss: 8.0894 - val_accuracy: 0.6196\n",
      "Epoch 10/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 8.2116 - accuracy: 0.3969 - val_loss: 8.0644 - val_accuracy: 0.4865\n",
      "Epoch 11/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 8.0698 - accuracy: 0.4518 - val_loss: 7.9578 - val_accuracy: 0.5472\n",
      "Epoch 12/350\n",
      "128/128 [==============================] - 37s 291ms/step - loss: 7.9537 - accuracy: 0.4385 - val_loss: 7.7507 - val_accuracy: 0.6269\n",
      "Epoch 13/350\n",
      "128/128 [==============================] - 37s 291ms/step - loss: 7.0441 - accuracy: 0.9639 - val_loss: 8.1418 - val_accuracy: 0.6197\n",
      "Epoch 14/350\n",
      "128/128 [==============================] - 37s 291ms/step - loss: 7.3610 - accuracy: 0.7896 - val_loss: 7.6803 - val_accuracy: 0.6197\n",
      "Epoch 15/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 7.5010 - accuracy: 0.5274 - val_loss: 7.4686 - val_accuracy: 0.4788\n",
      "Epoch 16/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 7.5281 - accuracy: 0.4100 - val_loss: 7.3521 - val_accuracy: 0.5437\n",
      "Epoch 17/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 7.4144 - accuracy: 0.4223 - val_loss: 7.2282 - val_accuracy: 0.5405\n",
      "Epoch 18/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 6.9433 - accuracy: 0.6846 - val_loss: 7.0409 - val_accuracy: 0.6232\n",
      "Epoch 19/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 7.2177 - accuracy: 0.4112 - val_loss: 7.0111 - val_accuracy: 0.5526\n",
      "Epoch 20/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 7.0962 - accuracy: 0.4556 - val_loss: 6.9187 - val_accuracy: 0.5503\n",
      "Epoch 21/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 7.0033 - accuracy: 0.4328 - val_loss: 6.7676 - val_accuracy: 0.6398\n",
      "Epoch 22/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 6.1199 - accuracy: 0.9564 - val_loss: 7.1941 - val_accuracy: 0.6197\n",
      "Epoch 23/350\n",
      "128/128 [==============================] - 37s 295ms/step - loss: 6.4094 - accuracy: 0.7953 - val_loss: 6.7468 - val_accuracy: 0.6197\n",
      "Epoch 24/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 6.5789 - accuracy: 0.5417 - val_loss: 6.5231 - val_accuracy: 0.5522\n",
      "Epoch 25/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 6.6514 - accuracy: 0.4194 - val_loss: 6.4416 - val_accuracy: 0.5510\n",
      "Epoch 26/350\n",
      "128/128 [==============================] - 37s 291ms/step - loss: 6.5564 - accuracy: 0.4263 - val_loss: 6.3530 - val_accuracy: 0.5371\n",
      "Epoch 27/350\n",
      "128/128 [==============================] - 37s 291ms/step - loss: 6.0769 - accuracy: 0.6869 - val_loss: 6.1720 - val_accuracy: 0.6284\n",
      "Epoch 28/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 6.3964 - accuracy: 0.4151 - val_loss: 6.1559 - val_accuracy: 0.5547\n",
      "Epoch 29/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 6.2915 - accuracy: 0.4614 - val_loss: 6.0790 - val_accuracy: 0.5546\n",
      "Epoch 30/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 6.2239 - accuracy: 0.4338 - val_loss: 5.9619 - val_accuracy: 0.6350\n",
      "Epoch 31/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 5.3614 - accuracy: 0.9489 - val_loss: 6.4427 - val_accuracy: 0.6197\n",
      "Epoch 32/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 5.6213 - accuracy: 0.8029 - val_loss: 5.9834 - val_accuracy: 0.6197\n",
      "Epoch 33/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 5.8262 - accuracy: 0.5546 - val_loss: 5.7610 - val_accuracy: 0.5528\n",
      "Epoch 34/350\n",
      "128/128 [==============================] - 37s 292ms/step - loss: 5.9279 - accuracy: 0.4310 - val_loss: 5.6939 - val_accuracy: 0.5511\n",
      "Epoch 35/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 5.8490 - accuracy: 0.4316 - val_loss: 5.6286 - val_accuracy: 0.5500\n",
      "Epoch 36/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 5.3718 - accuracy: 0.6864 - val_loss: 5.4712 - val_accuracy: 0.6293\n",
      "Epoch 37/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 5.7174 - accuracy: 0.4273 - val_loss: 5.4566 - val_accuracy: 0.5549\n",
      "Epoch 38/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 5.6269 - accuracy: 0.4625 - val_loss: 5.3893 - val_accuracy: 0.6170\n",
      "Epoch 39/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 5.5752 - accuracy: 0.4311 - val_loss: 5.2993 - val_accuracy: 0.6079\n",
      "Epoch 40/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 4.7439 - accuracy: 0.9363 - val_loss: 5.7958 - val_accuracy: 0.6197\n",
      "Epoch 41/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 4.9587 - accuracy: 0.8116 - val_loss: 5.3296 - val_accuracy: 0.6197\n",
      "Epoch 42/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 5.2059 - accuracy: 0.5564 - val_loss: 5.1335 - val_accuracy: 0.5516\n",
      "Epoch 43/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 5.3286 - accuracy: 0.4371 - val_loss: 5.0805 - val_accuracy: 0.5541\n",
      "Epoch 44/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 5.2612 - accuracy: 0.4397 - val_loss: 5.0396 - val_accuracy: 0.5462\n",
      "Epoch 45/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 4.7914 - accuracy: 0.6872 - val_loss: 4.8914 - val_accuracy: 0.6332\n",
      "Epoch 46/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 5.1539 - accuracy: 0.4257 - val_loss: 4.8818 - val_accuracy: 0.5552\n",
      "Epoch 47/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 5.0727 - accuracy: 0.4670 - val_loss: 4.8255 - val_accuracy: 0.6199\n",
      "Epoch 48/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 5.0334 - accuracy: 0.4396 - val_loss: 4.7488 - val_accuracy: 0.6097\n",
      "Epoch 49/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 4.2367 - accuracy: 0.9243 - val_loss: 5.2760 - val_accuracy: 0.6197\n",
      "Epoch 50/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 4.4086 - accuracy: 0.8173 - val_loss: 4.7809 - val_accuracy: 0.6197\n",
      "Epoch 51/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 4.6823 - accuracy: 0.5700 - val_loss: 4.6178 - val_accuracy: 0.5569\n",
      "Epoch 52/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 4.8279 - accuracy: 0.4415 - val_loss: 4.5706 - val_accuracy: 0.5589\n",
      "Epoch 53/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 4.7681 - accuracy: 0.4429 - val_loss: 4.5403 - val_accuracy: 0.5485\n",
      "Epoch 54/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 4.3074 - accuracy: 0.6907 - val_loss: 4.4090 - val_accuracy: 0.6358\n",
      "Epoch 55/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 4.6811 - accuracy: 0.4349 - val_loss: 4.4051 - val_accuracy: 0.5577\n",
      "Epoch 56/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 37s 293ms/step - loss: 4.6091 - accuracy: 0.4697 - val_loss: 4.3553 - val_accuracy: 0.6227\n",
      "Epoch 57/350\n",
      "128/128 [==============================] - 37s 293ms/step - loss: 4.5788 - accuracy: 0.4458 - val_loss: 4.2920 - val_accuracy: 0.6103\n",
      "Epoch 58/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 3.8199 - accuracy: 0.9106 - val_loss: 4.8275 - val_accuracy: 0.6197\n",
      "Epoch 59/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 3.9527 - accuracy: 0.8228 - val_loss: 4.3050 - val_accuracy: 0.6197\n",
      "Epoch 60/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 4.2415 - accuracy: 0.5830 - val_loss: 4.1818 - val_accuracy: 0.5629\n",
      "Epoch 61/350\n",
      "128/128 [==============================] - 37s 295ms/step - loss: 4.4072 - accuracy: 0.4489 - val_loss: 4.1419 - val_accuracy: 0.5657\n",
      "Epoch 62/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 4.3561 - accuracy: 0.4502 - val_loss: 4.1223 - val_accuracy: 0.5549\n",
      "Epoch 63/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 3.9052 - accuracy: 0.6890 - val_loss: 4.0046 - val_accuracy: 0.6432\n",
      "Epoch 64/350\n",
      "128/128 [==============================] - 37s 295ms/step - loss: 4.2836 - accuracy: 0.4473 - val_loss: 4.0056 - val_accuracy: 0.5582\n",
      "Epoch 65/350\n",
      "128/128 [==============================] - 37s 295ms/step - loss: 4.2176 - accuracy: 0.4783 - val_loss: 3.9636 - val_accuracy: 0.6296\n",
      "Epoch 66/350\n",
      "128/128 [==============================] - 37s 294ms/step - loss: 4.2000 - accuracy: 0.4543 - val_loss: 3.9125 - val_accuracy: 0.6166\n",
      "Epoch 67/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 3.4728 - accuracy: 0.8978 - val_loss: 4.4523 - val_accuracy: 0.6197\n",
      "Epoch 68/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 3.5676 - accuracy: 0.8248 - val_loss: 3.8981 - val_accuracy: 0.6197\n",
      "Epoch 69/350\n",
      "128/128 [==============================] - 38s 295ms/step - loss: 3.8663 - accuracy: 0.5978 - val_loss: 3.8185 - val_accuracy: 0.5711\n",
      "Epoch 70/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 4.0544 - accuracy: 0.4595 - val_loss: 3.7859 - val_accuracy: 0.6327\n",
      "Epoch 71/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 4.0123 - accuracy: 0.4555 - val_loss: 3.7659 - val_accuracy: 0.5630\n",
      "Epoch 72/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 3.5694 - accuracy: 0.6901 - val_loss: 3.6682 - val_accuracy: 0.6494\n",
      "Epoch 73/350\n",
      "128/128 [==============================] - 38s 295ms/step - loss: 3.9475 - accuracy: 0.4555 - val_loss: 3.6674 - val_accuracy: 0.5643\n",
      "Epoch 74/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 3.8940 - accuracy: 0.4833 - val_loss: 3.6338 - val_accuracy: 0.6341\n",
      "Epoch 75/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 3.8759 - accuracy: 0.4642 - val_loss: 3.5880 - val_accuracy: 0.6251\n",
      "Epoch 76/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 3.1852 - accuracy: 0.8865 - val_loss: 4.1332 - val_accuracy: 0.6197\n",
      "Epoch 77/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 3.2456 - accuracy: 0.8254 - val_loss: 3.5555 - val_accuracy: 0.6197\n",
      "Epoch 78/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 3.5433 - accuracy: 0.6201 - val_loss: 3.5152 - val_accuracy: 0.5729\n",
      "Epoch 79/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 3.7557 - accuracy: 0.4687 - val_loss: 3.4818 - val_accuracy: 0.6417\n",
      "Epoch 80/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 3.7169 - accuracy: 0.4734 - val_loss: 3.4752 - val_accuracy: 0.5710\n",
      "Epoch 81/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 3.2869 - accuracy: 0.6944 - val_loss: 3.3848 - val_accuracy: 0.6448\n",
      "Epoch 82/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 3.6644 - accuracy: 0.4723 - val_loss: 3.3887 - val_accuracy: 0.5727\n",
      "Epoch 83/350\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 3.6165 - accuracy: 0.4958 - val_loss: 3.3563 - val_accuracy: 0.6377\n",
      "Epoch 84/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 3.6091 - accuracy: 0.4719 - val_loss: 3.3293 - val_accuracy: 0.6305\n",
      "Epoch 85/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 2.9480 - accuracy: 0.8745 - val_loss: 3.8781 - val_accuracy: 0.6197\n",
      "Epoch 86/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 2.9799 - accuracy: 0.8278 - val_loss: 3.2767 - val_accuracy: 0.6202\n",
      "Epoch 87/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 3.2748 - accuracy: 0.6347 - val_loss: 3.2569 - val_accuracy: 0.5821\n",
      "Epoch 88/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 3.5074 - accuracy: 0.4811 - val_loss: 3.2341 - val_accuracy: 0.6473\n",
      "Epoch 89/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 3.4732 - accuracy: 0.4764 - val_loss: 3.2238 - val_accuracy: 0.5802\n",
      "Epoch 90/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 3.0492 - accuracy: 0.6985 - val_loss: 3.1482 - val_accuracy: 0.6700\n",
      "Epoch 91/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 3.4302 - accuracy: 0.4772 - val_loss: 3.1534 - val_accuracy: 0.6362\n",
      "Epoch 92/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 3.3829 - accuracy: 0.5057 - val_loss: 3.1249 - val_accuracy: 0.6437\n",
      "Epoch 93/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 3.3804 - accuracy: 0.4832 - val_loss: 3.1002 - val_accuracy: 0.6370\n",
      "Epoch 94/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 2.7524 - accuracy: 0.8620 - val_loss: 3.6372 - val_accuracy: 0.6197\n",
      "Epoch 95/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 2.7460 - accuracy: 0.8292 - val_loss: 3.0420 - val_accuracy: 0.6263\n",
      "Epoch 96/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 3.0444 - accuracy: 0.6523 - val_loss: 3.0433 - val_accuracy: 0.5862\n",
      "Epoch 97/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 3.2924 - accuracy: 0.4955 - val_loss: 3.0322 - val_accuracy: 0.6187\n",
      "Epoch 98/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 3.2687 - accuracy: 0.4845 - val_loss: 3.0148 - val_accuracy: 0.5888\n",
      "Epoch 99/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 2.8501 - accuracy: 0.6953 - val_loss: 2.9512 - val_accuracy: 0.6445\n",
      "Epoch 100/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 3.2283 - accuracy: 0.4893 - val_loss: 2.9575 - val_accuracy: 0.6478\n",
      "Epoch 101/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 3.1908 - accuracy: 0.5150 - val_loss: 2.9260 - val_accuracy: 0.6500\n",
      "Epoch 102/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 3.1918 - accuracy: 0.4911 - val_loss: 2.9112 - val_accuracy: 0.6478\n",
      "Epoch 103/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 2.5962 - accuracy: 0.8530 - val_loss: 3.4518 - val_accuracy: 0.6197\n",
      "Epoch 104/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 2.5572 - accuracy: 0.8315 - val_loss: 2.8528 - val_accuracy: 0.6415\n",
      "Epoch 105/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 2.8490 - accuracy: 0.6705 - val_loss: 2.8549 - val_accuracy: 0.6500\n",
      "Epoch 106/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 3.1157 - accuracy: 0.5010 - val_loss: 2.8531 - val_accuracy: 0.6516\n",
      "Epoch 107/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 3.0929 - accuracy: 0.4988 - val_loss: 2.8409 - val_accuracy: 0.5913\n",
      "Epoch 108/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 2.6789 - accuracy: 0.7062 - val_loss: 2.7823 - val_accuracy: 0.6774\n",
      "Epoch 109/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 3.0593 - accuracy: 0.4975 - val_loss: 2.7945 - val_accuracy: 0.6395\n",
      "Epoch 110/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 3.0232 - accuracy: 0.5182 - val_loss: 2.7626 - val_accuracy: 0.6917\n",
      "Epoch 111/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 3.0275 - accuracy: 0.5004 - val_loss: 2.7438 - val_accuracy: 0.6836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 2.4621 - accuracy: 0.8427 - val_loss: 3.3050 - val_accuracy: 0.6197\n",
      "Epoch 113/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 2.3959 - accuracy: 0.8322 - val_loss: 2.6937 - val_accuracy: 0.6546\n",
      "Epoch 114/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 2.6796 - accuracy: 0.6863 - val_loss: 2.7022 - val_accuracy: 0.6479\n",
      "Epoch 115/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 2.9616 - accuracy: 0.5081 - val_loss: 2.6870 - val_accuracy: 0.6563\n",
      "Epoch 116/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 2.9444 - accuracy: 0.5003 - val_loss: 2.6875 - val_accuracy: 0.6014\n",
      "Epoch 117/350\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 2.5382 - accuracy: 0.7087 - val_loss: 2.6292 - val_accuracy: 0.6474\n",
      "Epoch 118/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 2.9140 - accuracy: 0.5074 - val_loss: 2.6475 - val_accuracy: 0.6555\n",
      "Epoch 119/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 2.8851 - accuracy: 0.5239 - val_loss: 2.6150 - val_accuracy: 0.6516\n",
      "Epoch 120/350\n",
      "128/128 [==============================] - 38s 303ms/step - loss: 2.8904 - accuracy: 0.5075 - val_loss: 2.6123 - val_accuracy: 0.6729\n",
      "Epoch 121/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 2.3511 - accuracy: 0.8316 - val_loss: 3.1401 - val_accuracy: 0.6197\n",
      "Epoch 122/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 2.2545 - accuracy: 0.8345 - val_loss: 2.5606 - val_accuracy: 0.6658\n",
      "Epoch 123/350\n",
      "128/128 [==============================] - 38s 298ms/step - loss: 2.5409 - accuracy: 0.6937 - val_loss: 2.5701 - val_accuracy: 0.6460\n",
      "Epoch 124/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.8337 - accuracy: 0.5128 - val_loss: 2.5537 - val_accuracy: 0.6583\n",
      "Epoch 125/350\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 2.8200 - accuracy: 0.5046 - val_loss: 2.5593 - val_accuracy: 0.6563\n",
      "Epoch 126/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.4194 - accuracy: 0.7069 - val_loss: 2.5030 - val_accuracy: 0.6614\n",
      "Epoch 127/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.7872 - accuracy: 0.5141 - val_loss: 2.5207 - val_accuracy: 0.6574\n",
      "Epoch 128/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.7612 - accuracy: 0.5305 - val_loss: 2.4872 - val_accuracy: 0.6943\n",
      "Epoch 129/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.7679 - accuracy: 0.5110 - val_loss: 2.4902 - val_accuracy: 0.6689\n",
      "Epoch 130/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.2577 - accuracy: 0.8222 - val_loss: 3.0312 - val_accuracy: 0.6197\n",
      "Epoch 131/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1252 - accuracy: 0.8386 - val_loss: 2.4443 - val_accuracy: 0.6799\n",
      "Epoch 132/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.4127 - accuracy: 0.7091 - val_loss: 2.4495 - val_accuracy: 0.6537\n",
      "Epoch 133/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.7211 - accuracy: 0.5110 - val_loss: 2.4390 - val_accuracy: 0.6622\n",
      "Epoch 134/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.7078 - accuracy: 0.5065 - val_loss: 2.4440 - val_accuracy: 0.6557\n",
      "Epoch 135/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.3058 - accuracy: 0.7147 - val_loss: 2.3921 - val_accuracy: 0.6828\n",
      "Epoch 136/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.6772 - accuracy: 0.5194 - val_loss: 2.4116 - val_accuracy: 0.6582\n",
      "Epoch 137/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.6535 - accuracy: 0.5339 - val_loss: 2.3796 - val_accuracy: 0.6890\n",
      "Epoch 138/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.6640 - accuracy: 0.5092 - val_loss: 2.3913 - val_accuracy: 0.6534\n",
      "Epoch 139/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1759 - accuracy: 0.8102 - val_loss: 2.9167 - val_accuracy: 0.6199\n",
      "Epoch 140/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.0243 - accuracy: 0.8400 - val_loss: 2.3505 - val_accuracy: 0.6370\n",
      "Epoch 141/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.2950 - accuracy: 0.7203 - val_loss: 2.3480 - val_accuracy: 0.6534\n",
      "Epoch 142/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.6204 - accuracy: 0.5185 - val_loss: 2.3391 - val_accuracy: 0.6614\n",
      "Epoch 143/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.6062 - accuracy: 0.5145 - val_loss: 2.3430 - val_accuracy: 0.6566\n",
      "Epoch 144/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.2128 - accuracy: 0.7152 - val_loss: 2.2962 - val_accuracy: 0.6780\n",
      "Epoch 145/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.5840 - accuracy: 0.5158 - val_loss: 2.3170 - val_accuracy: 0.6592\n",
      "Epoch 146/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.5621 - accuracy: 0.5349 - val_loss: 2.2904 - val_accuracy: 0.6865\n",
      "Epoch 147/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.5717 - accuracy: 0.5165 - val_loss: 2.3011 - val_accuracy: 0.6592\n",
      "Epoch 148/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.1083 - accuracy: 0.8005 - val_loss: 2.8112 - val_accuracy: 0.6204\n",
      "Epoch 149/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 1.9347 - accuracy: 0.8419 - val_loss: 2.2595 - val_accuracy: 0.6774\n",
      "Epoch 150/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1953 - accuracy: 0.7301 - val_loss: 2.2559 - val_accuracy: 0.6578\n",
      "Epoch 151/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.5360 - accuracy: 0.5120 - val_loss: 2.2542 - val_accuracy: 0.6574\n",
      "Epoch 152/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.5250 - accuracy: 0.5073 - val_loss: 2.2543 - val_accuracy: 0.6570\n",
      "Epoch 153/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1261 - accuracy: 0.7202 - val_loss: 2.2166 - val_accuracy: 0.6833\n",
      "Epoch 154/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.4982 - accuracy: 0.5217 - val_loss: 2.2302 - val_accuracy: 0.6596\n",
      "Epoch 155/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.4742 - accuracy: 0.5455 - val_loss: 2.2070 - val_accuracy: 0.6851\n",
      "Epoch 156/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.4904 - accuracy: 0.5153 - val_loss: 2.2154 - val_accuracy: 0.6605\n",
      "Epoch 157/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.0425 - accuracy: 0.7935 - val_loss: 2.7531 - val_accuracy: 0.6219\n",
      "Epoch 158/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8610 - accuracy: 0.8407 - val_loss: 2.1817 - val_accuracy: 0.6371\n",
      "Epoch 159/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 2.0843 - accuracy: 0.7441 - val_loss: 2.1776 - val_accuracy: 0.6517\n",
      "Epoch 160/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.4542 - accuracy: 0.5163 - val_loss: 2.1827 - val_accuracy: 0.6627\n",
      "Epoch 161/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.4423 - accuracy: 0.5175 - val_loss: 2.1756 - val_accuracy: 0.6549\n",
      "Epoch 162/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.0497 - accuracy: 0.7261 - val_loss: 2.1386 - val_accuracy: 0.6786\n",
      "Epoch 163/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 2.4218 - accuracy: 0.5179 - val_loss: 2.1546 - val_accuracy: 0.6573\n",
      "Epoch 164/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.3974 - accuracy: 0.5421 - val_loss: 2.1332 - val_accuracy: 0.6765\n",
      "Epoch 165/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.4144 - accuracy: 0.5167 - val_loss: 2.1410 - val_accuracy: 0.6599\n",
      "Epoch 166/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 1.9934 - accuracy: 0.7814 - val_loss: 2.6830 - val_accuracy: 0.6219\n",
      "Epoch 167/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7944 - accuracy: 0.8419 - val_loss: 2.1060 - val_accuracy: 0.6732\n",
      "Epoch 168/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.9904 - accuracy: 0.7574 - val_loss: 2.1087 - val_accuracy: 0.6508\n",
      "Epoch 169/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.3847 - accuracy: 0.5162 - val_loss: 2.1050 - val_accuracy: 0.6591\n",
      "Epoch 170/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.3721 - accuracy: 0.5158 - val_loss: 2.1038 - val_accuracy: 0.6487\n",
      "Epoch 171/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.9823 - accuracy: 0.7257 - val_loss: 2.0997 - val_accuracy: 0.6750\n",
      "Epoch 172/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.3534 - accuracy: 0.5225 - val_loss: 2.0824 - val_accuracy: 0.6607\n",
      "Epoch 173/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.3286 - accuracy: 0.5482 - val_loss: 2.0661 - val_accuracy: 0.6720\n",
      "Epoch 174/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 2.3461 - accuracy: 0.5148 - val_loss: 2.0779 - val_accuracy: 0.6610\n",
      "Epoch 175/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.9449 - accuracy: 0.7711 - val_loss: 2.7073 - val_accuracy: 0.6204\n",
      "Epoch 176/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7247 - accuracy: 0.8413 - val_loss: 2.0450 - val_accuracy: 0.6809\n",
      "Epoch 177/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.9065 - accuracy: 0.7646 - val_loss: 2.0539 - val_accuracy: 0.6448\n",
      "Epoch 178/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 2.3221 - accuracy: 0.5196 - val_loss: 2.0517 - val_accuracy: 0.6592\n",
      "Epoch 179/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 2.3074 - accuracy: 0.5193 - val_loss: 2.0366 - val_accuracy: 0.6611\n",
      "Epoch 180/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.9188 - accuracy: 0.7271 - val_loss: 2.0179 - val_accuracy: 0.6736\n",
      "Epoch 181/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.2859 - accuracy: 0.5243 - val_loss: 2.0179 - val_accuracy: 0.6562\n",
      "Epoch 182/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.2618 - accuracy: 0.5534 - val_loss: 2.0079 - val_accuracy: 0.6728\n",
      "Epoch 183/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.2839 - accuracy: 0.5155 - val_loss: 2.0111 - val_accuracy: 0.6579\n",
      "Epoch 184/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8934 - accuracy: 0.7644 - val_loss: 2.7421 - val_accuracy: 0.6197\n",
      "Epoch 185/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6783 - accuracy: 0.8391 - val_loss: 1.9856 - val_accuracy: 0.6741\n",
      "Epoch 186/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.8233 - accuracy: 0.7783 - val_loss: 1.9910 - val_accuracy: 0.6450\n",
      "Epoch 187/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 2.2614 - accuracy: 0.5189 - val_loss: 1.9960 - val_accuracy: 0.6583\n",
      "Epoch 188/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.2484 - accuracy: 0.5191 - val_loss: 1.9752 - val_accuracy: 0.6543\n",
      "Epoch 189/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.8587 - accuracy: 0.7288 - val_loss: 1.9683 - val_accuracy: 0.6759\n",
      "Epoch 190/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.2264 - accuracy: 0.5268 - val_loss: 1.9616 - val_accuracy: 0.6611\n",
      "Epoch 191/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.2023 - accuracy: 0.5527 - val_loss: 1.9685 - val_accuracy: 0.6755\n",
      "Epoch 192/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.2294 - accuracy: 0.5128 - val_loss: 1.9544 - val_accuracy: 0.6592\n",
      "Epoch 193/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8421 - accuracy: 0.7612 - val_loss: 2.7537 - val_accuracy: 0.6197\n",
      "Epoch 194/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6384 - accuracy: 0.8375 - val_loss: 1.9330 - val_accuracy: 0.6739\n",
      "Epoch 195/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7469 - accuracy: 0.7914 - val_loss: 1.9345 - val_accuracy: 0.6442\n",
      "Epoch 196/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.2085 - accuracy: 0.5173 - val_loss: 1.9446 - val_accuracy: 0.6566\n",
      "Epoch 197/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1941 - accuracy: 0.5204 - val_loss: 1.9214 - val_accuracy: 0.6587\n",
      "Epoch 198/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8120 - accuracy: 0.7242 - val_loss: 1.9125 - val_accuracy: 0.6654\n",
      "Epoch 199/350\n",
      "128/128 [==============================] - 38s 300ms/step - loss: 2.1623 - accuracy: 0.5347 - val_loss: 1.9109 - val_accuracy: 0.6553\n",
      "Epoch 200/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1473 - accuracy: 0.5588 - val_loss: 1.9150 - val_accuracy: 0.6666\n",
      "Epoch 201/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1792 - accuracy: 0.5134 - val_loss: 1.9118 - val_accuracy: 0.6613\n",
      "Epoch 202/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8072 - accuracy: 0.7519 - val_loss: 2.7425 - val_accuracy: 0.6197\n",
      "Epoch 203/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.5968 - accuracy: 0.8359 - val_loss: 1.8812 - val_accuracy: 0.6635\n",
      "Epoch 204/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6727 - accuracy: 0.8015 - val_loss: 1.8798 - val_accuracy: 0.6383\n",
      "Epoch 205/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1580 - accuracy: 0.5169 - val_loss: 1.8854 - val_accuracy: 0.6532\n",
      "Epoch 206/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 2.1393 - accuracy: 0.5225 - val_loss: 1.8630 - val_accuracy: 0.6557\n",
      "Epoch 207/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7695 - accuracy: 0.7250 - val_loss: 1.8676 - val_accuracy: 0.6642\n",
      "Epoch 208/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1065 - accuracy: 0.5376 - val_loss: 1.8538 - val_accuracy: 0.6584\n",
      "Epoch 209/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1003 - accuracy: 0.5580 - val_loss: 1.8615 - val_accuracy: 0.6663\n",
      "Epoch 210/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 2.1255 - accuracy: 0.5187 - val_loss: 1.8594 - val_accuracy: 0.6606\n",
      "Epoch 211/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7556 - accuracy: 0.7437 - val_loss: 2.7406 - val_accuracy: 0.6197\n",
      "Epoch 212/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.5694 - accuracy: 0.8325 - val_loss: 1.8443 - val_accuracy: 0.6694\n",
      "Epoch 213/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6075 - accuracy: 0.8100 - val_loss: 1.8301 - val_accuracy: 0.6275\n",
      "Epoch 214/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.1101 - accuracy: 0.5187 - val_loss: 1.8375 - val_accuracy: 0.6511\n",
      "Epoch 215/350\n",
      "128/128 [==============================] - 39s 306ms/step - loss: 2.0975 - accuracy: 0.5206 - val_loss: 1.8188 - val_accuracy: 0.6580\n",
      "Epoch 216/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7301 - accuracy: 0.7219 - val_loss: 1.8320 - val_accuracy: 0.6626\n",
      "Epoch 217/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.0544 - accuracy: 0.5421 - val_loss: 1.8080 - val_accuracy: 0.6528\n",
      "Epoch 218/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.0526 - accuracy: 0.5610 - val_loss: 1.8217 - val_accuracy: 0.6614\n",
      "Epoch 219/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 2.0824 - accuracy: 0.5167 - val_loss: 1.8050 - val_accuracy: 0.6621\n",
      "Epoch 220/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7188 - accuracy: 0.7383 - val_loss: 2.7072 - val_accuracy: 0.6197\n",
      "Epoch 221/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.5290 - accuracy: 0.8342 - val_loss: 1.7963 - val_accuracy: 0.6539\n",
      "Epoch 222/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 38s 301ms/step - loss: 1.5454 - accuracy: 0.8185 - val_loss: 1.7926 - val_accuracy: 0.6632\n",
      "Epoch 223/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.0659 - accuracy: 0.5200 - val_loss: 1.8016 - val_accuracy: 0.6564\n",
      "Epoch 224/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.0505 - accuracy: 0.5286 - val_loss: 1.7742 - val_accuracy: 0.6560\n",
      "Epoch 225/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7005 - accuracy: 0.7148 - val_loss: 1.7899 - val_accuracy: 0.6624\n",
      "Epoch 226/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.9971 - accuracy: 0.5487 - val_loss: 1.7751 - val_accuracy: 0.6488\n",
      "Epoch 227/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.0065 - accuracy: 0.5605 - val_loss: 1.7892 - val_accuracy: 0.6579\n",
      "Epoch 228/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.0408 - accuracy: 0.5187 - val_loss: 1.7687 - val_accuracy: 0.6629\n",
      "Epoch 229/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6964 - accuracy: 0.7330 - val_loss: 2.6043 - val_accuracy: 0.6197\n",
      "Epoch 230/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.4849 - accuracy: 0.8352 - val_loss: 1.7555 - val_accuracy: 0.6605\n",
      "Epoch 231/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.4923 - accuracy: 0.8303 - val_loss: 1.7537 - val_accuracy: 0.6571\n",
      "Epoch 232/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.0332 - accuracy: 0.5095 - val_loss: 1.7744 - val_accuracy: 0.6584\n",
      "Epoch 233/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 2.0107 - accuracy: 0.5242 - val_loss: 1.7401 - val_accuracy: 0.6827\n",
      "Epoch 234/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6806 - accuracy: 0.7063 - val_loss: 1.7417 - val_accuracy: 0.6645\n",
      "Epoch 235/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.9398 - accuracy: 0.5606 - val_loss: 1.7269 - val_accuracy: 0.6587\n",
      "Epoch 236/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.9681 - accuracy: 0.5624 - val_loss: 1.7539 - val_accuracy: 0.6580\n",
      "Epoch 237/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 2.0026 - accuracy: 0.5206 - val_loss: 1.7336 - val_accuracy: 0.6651\n",
      "Epoch 238/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6809 - accuracy: 0.7158 - val_loss: 2.5139 - val_accuracy: 0.6197\n",
      "Epoch 239/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.4315 - accuracy: 0.8431 - val_loss: 1.7218 - val_accuracy: 0.6548\n",
      "Epoch 240/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.4349 - accuracy: 0.8393 - val_loss: 1.7106 - val_accuracy: 0.6665\n",
      "Epoch 241/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.9859 - accuracy: 0.5217 - val_loss: 1.7404 - val_accuracy: 0.6555\n",
      "Epoch 242/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.9739 - accuracy: 0.5232 - val_loss: 1.7114 - val_accuracy: 0.6821\n",
      "Epoch 243/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6666 - accuracy: 0.6968 - val_loss: 1.7153 - val_accuracy: 0.6623\n",
      "Epoch 244/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.8809 - accuracy: 0.5683 - val_loss: 1.6889 - val_accuracy: 0.6613\n",
      "Epoch 245/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.9318 - accuracy: 0.5567 - val_loss: 1.7157 - val_accuracy: 0.6591\n",
      "Epoch 246/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.9659 - accuracy: 0.5209 - val_loss: 1.7106 - val_accuracy: 0.6622\n",
      "Epoch 247/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6605 - accuracy: 0.7070 - val_loss: 2.4402 - val_accuracy: 0.6198\n",
      "Epoch 248/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.3878 - accuracy: 0.8489 - val_loss: 1.6989 - val_accuracy: 0.6542\n",
      "Epoch 249/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.3970 - accuracy: 0.8416 - val_loss: 1.7044 - val_accuracy: 0.6573\n",
      "Epoch 250/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.9586 - accuracy: 0.5153 - val_loss: 1.7101 - val_accuracy: 0.6557\n",
      "Epoch 251/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.9431 - accuracy: 0.5209 - val_loss: 1.6634 - val_accuracy: 0.6538\n",
      "Epoch 252/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6477 - accuracy: 0.6899 - val_loss: 1.6831 - val_accuracy: 0.6621\n",
      "Epoch 253/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.8272 - accuracy: 0.5796 - val_loss: 1.6537 - val_accuracy: 0.6583\n",
      "Epoch 254/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.9011 - accuracy: 0.5565 - val_loss: 1.6799 - val_accuracy: 0.6596\n",
      "Epoch 255/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.9232 - accuracy: 0.5269 - val_loss: 1.6915 - val_accuracy: 0.6576\n",
      "Epoch 256/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6510 - accuracy: 0.6949 - val_loss: 2.2831 - val_accuracy: 0.6208\n",
      "Epoch 257/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.3360 - accuracy: 0.8612 - val_loss: 1.6854 - val_accuracy: 0.6530\n",
      "Epoch 258/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.3602 - accuracy: 0.8424 - val_loss: 1.6873 - val_accuracy: 0.6504\n",
      "Epoch 259/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.9244 - accuracy: 0.5139 - val_loss: 1.6904 - val_accuracy: 0.6506\n",
      "Epoch 260/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.9065 - accuracy: 0.5237 - val_loss: 1.6494 - val_accuracy: 0.6728\n",
      "Epoch 261/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6394 - accuracy: 0.6728 - val_loss: 1.6389 - val_accuracy: 0.6655\n",
      "Epoch 262/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7668 - accuracy: 0.5954 - val_loss: 1.6266 - val_accuracy: 0.6592\n",
      "Epoch 263/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.8674 - accuracy: 0.5609 - val_loss: 1.6452 - val_accuracy: 0.6628\n",
      "Epoch 264/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8892 - accuracy: 0.5316 - val_loss: 1.6437 - val_accuracy: 0.6638\n",
      "Epoch 265/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6377 - accuracy: 0.6890 - val_loss: 2.1836 - val_accuracy: 0.6227\n",
      "Epoch 266/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.2819 - accuracy: 0.8726 - val_loss: 1.6734 - val_accuracy: 0.6594\n",
      "Epoch 267/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.3295 - accuracy: 0.8428 - val_loss: 1.6732 - val_accuracy: 0.6101\n",
      "Epoch 268/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8926 - accuracy: 0.5160 - val_loss: 1.6345 - val_accuracy: 0.6607\n",
      "Epoch 269/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.8735 - accuracy: 0.5308 - val_loss: 1.6078 - val_accuracy: 0.6814\n",
      "Epoch 270/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6283 - accuracy: 0.6638 - val_loss: 1.6125 - val_accuracy: 0.6653\n",
      "Epoch 271/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7133 - accuracy: 0.6051 - val_loss: 1.5917 - val_accuracy: 0.6552\n",
      "Epoch 272/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.8446 - accuracy: 0.5519 - val_loss: 1.6001 - val_accuracy: 0.6684\n",
      "Epoch 273/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8554 - accuracy: 0.5300 - val_loss: 1.6048 - val_accuracy: 0.6644\n",
      "Epoch 274/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6242 - accuracy: 0.6800 - val_loss: 2.0702 - val_accuracy: 0.6266\n",
      "Epoch 275/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.2217 - accuracy: 0.8875 - val_loss: 1.6652 - val_accuracy: 0.6612\n",
      "Epoch 276/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.3050 - accuracy: 0.8421 - val_loss: 1.6203 - val_accuracy: 0.6560\n",
      "Epoch 277/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8597 - accuracy: 0.5179 - val_loss: 1.6125 - val_accuracy: 0.6590\n",
      "Epoch 278/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8429 - accuracy: 0.5294 - val_loss: 1.5780 - val_accuracy: 0.6711\n",
      "Epoch 279/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6206 - accuracy: 0.6575 - val_loss: 1.5774 - val_accuracy: 0.6667\n",
      "Epoch 280/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6601 - accuracy: 0.6189 - val_loss: 1.5616 - val_accuracy: 0.6564\n",
      "Epoch 281/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.8175 - accuracy: 0.5489 - val_loss: 1.5602 - val_accuracy: 0.6727\n",
      "Epoch 282/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8184 - accuracy: 0.5439 - val_loss: 1.5915 - val_accuracy: 0.6634\n",
      "Epoch 283/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6142 - accuracy: 0.6642 - val_loss: 1.9475 - val_accuracy: 0.6323\n",
      "Epoch 284/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.1696 - accuracy: 0.9008 - val_loss: 1.6710 - val_accuracy: 0.6445\n",
      "Epoch 285/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.2788 - accuracy: 0.8400 - val_loss: 1.5804 - val_accuracy: 0.6562\n",
      "Epoch 286/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.8280 - accuracy: 0.5198 - val_loss: 1.5715 - val_accuracy: 0.6614\n",
      "Epoch 287/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.8135 - accuracy: 0.5356 - val_loss: 1.5443 - val_accuracy: 0.6516\n",
      "Epoch 288/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6159 - accuracy: 0.6413 - val_loss: 1.5529 - val_accuracy: 0.6680\n",
      "Epoch 289/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6121 - accuracy: 0.6288 - val_loss: 1.5329 - val_accuracy: 0.6587\n",
      "Epoch 290/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7930 - accuracy: 0.5431 - val_loss: 1.5239 - val_accuracy: 0.6812\n",
      "Epoch 291/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7833 - accuracy: 0.5507 - val_loss: 1.5648 - val_accuracy: 0.6623\n",
      "Epoch 292/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6035 - accuracy: 0.6609 - val_loss: 1.8484 - val_accuracy: 0.6394\n",
      "Epoch 293/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.1153 - accuracy: 0.9150 - val_loss: 1.6696 - val_accuracy: 0.6423\n",
      "Epoch 294/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.2575 - accuracy: 0.8383 - val_loss: 1.6011 - val_accuracy: 0.6462\n",
      "Epoch 295/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7984 - accuracy: 0.5190 - val_loss: 1.5438 - val_accuracy: 0.6615\n",
      "Epoch 296/350\n",
      "128/128 [==============================] - 38s 303ms/step - loss: 1.7863 - accuracy: 0.5314 - val_loss: 1.5302 - val_accuracy: 0.6560\n",
      "Epoch 297/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6067 - accuracy: 0.6312 - val_loss: 1.5188 - val_accuracy: 0.6703\n",
      "Epoch 298/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.5659 - accuracy: 0.6434 - val_loss: 1.5031 - val_accuracy: 0.6639\n",
      "Epoch 299/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7708 - accuracy: 0.5394 - val_loss: 1.5000 - val_accuracy: 0.6457\n",
      "Epoch 300/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7569 - accuracy: 0.5541 - val_loss: 1.5571 - val_accuracy: 0.6557\n",
      "Epoch 301/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6029 - accuracy: 0.6487 - val_loss: 1.6920 - val_accuracy: 0.6495\n",
      "Epoch 302/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.0682 - accuracy: 0.9266 - val_loss: 1.6942 - val_accuracy: 0.6476\n",
      "Epoch 303/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.2455 - accuracy: 0.8345 - val_loss: 1.6268 - val_accuracy: 0.6439\n",
      "Epoch 304/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7774 - accuracy: 0.5176 - val_loss: 1.5205 - val_accuracy: 0.6617\n",
      "Epoch 305/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7623 - accuracy: 0.5317 - val_loss: 1.5000 - val_accuracy: 0.6524\n",
      "Epoch 306/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6066 - accuracy: 0.6224 - val_loss: 1.4910 - val_accuracy: 0.6687\n",
      "Epoch 307/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.5185 - accuracy: 0.6512 - val_loss: 1.4812 - val_accuracy: 0.6611\n",
      "Epoch 308/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.7490 - accuracy: 0.5372 - val_loss: 1.4832 - val_accuracy: 0.6513\n",
      "Epoch 309/350\n",
      "128/128 [==============================] - 39s 306ms/step - loss: 1.7283 - accuracy: 0.5612 - val_loss: 1.5209 - val_accuracy: 0.6583\n",
      "Epoch 310/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.5940 - accuracy: 0.6367 - val_loss: 1.6131 - val_accuracy: 0.6532\n",
      "Epoch 311/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.0264 - accuracy: 0.9377 - val_loss: 1.7950 - val_accuracy: 0.6356\n",
      "Epoch 312/350\n",
      "128/128 [==============================] - 38s 303ms/step - loss: 1.2291 - accuracy: 0.8330 - val_loss: 1.6659 - val_accuracy: 0.6401\n",
      "Epoch 313/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7460 - accuracy: 0.5229 - val_loss: 1.5073 - val_accuracy: 0.6581\n",
      "Epoch 314/350\n",
      "128/128 [==============================] - 38s 303ms/step - loss: 1.7387 - accuracy: 0.5339 - val_loss: 1.4826 - val_accuracy: 0.6501\n",
      "Epoch 315/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6033 - accuracy: 0.6113 - val_loss: 1.4648 - val_accuracy: 0.6704\n",
      "Epoch 316/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.4737 - accuracy: 0.6667 - val_loss: 1.4597 - val_accuracy: 0.6660\n",
      "Epoch 317/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7295 - accuracy: 0.5359 - val_loss: 1.4646 - val_accuracy: 0.6554\n",
      "Epoch 318/350\n",
      "128/128 [==============================] - 38s 303ms/step - loss: 1.7014 - accuracy: 0.5659 - val_loss: 1.4796 - val_accuracy: 0.6643\n",
      "Epoch 319/350\n",
      "128/128 [==============================] - 38s 303ms/step - loss: 1.5899 - accuracy: 0.6257 - val_loss: 1.5305 - val_accuracy: 0.6595\n",
      "Epoch 320/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 0.9806 - accuracy: 0.9496 - val_loss: 1.9127 - val_accuracy: 0.6296\n",
      "Epoch 321/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.2260 - accuracy: 0.8240 - val_loss: 1.6555 - val_accuracy: 0.6406\n",
      "Epoch 322/350\n",
      "128/128 [==============================] - 38s 303ms/step - loss: 1.7090 - accuracy: 0.5318 - val_loss: 1.4957 - val_accuracy: 0.6590\n",
      "Epoch 323/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7161 - accuracy: 0.5344 - val_loss: 1.4723 - val_accuracy: 0.6502\n",
      "Epoch 324/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6016 - accuracy: 0.6030 - val_loss: 1.4561 - val_accuracy: 0.6724\n",
      "Epoch 325/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.4307 - accuracy: 0.6745 - val_loss: 1.4406 - val_accuracy: 0.6655\n",
      "Epoch 326/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.7081 - accuracy: 0.5315 - val_loss: 1.4460 - val_accuracy: 0.6594\n",
      "Epoch 327/350\n",
      "128/128 [==============================] - 38s 303ms/step - loss: 1.6739 - accuracy: 0.5681 - val_loss: 1.4612 - val_accuracy: 0.6635\n",
      "Epoch 328/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.5821 - accuracy: 0.6137 - val_loss: 1.4807 - val_accuracy: 0.6628\n",
      "Epoch 329/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 0.9357 - accuracy: 0.9612 - val_loss: 2.0732 - val_accuracy: 0.6218\n",
      "Epoch 330/350\n",
      "128/128 [==============================] - 39s 303ms/step - loss: 1.2423 - accuracy: 0.8106 - val_loss: 1.6127 - val_accuracy: 0.6432\n",
      "Epoch 331/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6633 - accuracy: 0.5437 - val_loss: 1.4652 - val_accuracy: 0.6634\n",
      "Epoch 332/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 38s 303ms/step - loss: 1.6944 - accuracy: 0.5325 - val_loss: 1.4666 - val_accuracy: 0.6473\n",
      "Epoch 333/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.5979 - accuracy: 0.5951 - val_loss: 1.4265 - val_accuracy: 0.6734\n",
      "Epoch 334/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.3918 - accuracy: 0.6882 - val_loss: 1.4190 - val_accuracy: 0.6641\n",
      "Epoch 335/350\n",
      "128/128 [==============================] - 39s 304ms/step - loss: 1.6835 - accuracy: 0.5341 - val_loss: 1.4288 - val_accuracy: 0.6574\n",
      "Epoch 336/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6540 - accuracy: 0.5673 - val_loss: 1.4335 - val_accuracy: 0.6616\n",
      "Epoch 337/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.5768 - accuracy: 0.6054 - val_loss: 1.4324 - val_accuracy: 0.6674\n",
      "Epoch 338/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 0.8978 - accuracy: 0.9697 - val_loss: 2.1310 - val_accuracy: 0.6208\n",
      "Epoch 339/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.2390 - accuracy: 0.8028 - val_loss: 1.5704 - val_accuracy: 0.6441\n",
      "Epoch 340/350\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1.6158 - accuracy: 0.5634 - val_loss: 1.4452 - val_accuracy: 0.6599\n",
      "Epoch 341/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6749 - accuracy: 0.5340 - val_loss: 1.4392 - val_accuracy: 0.6598\n",
      "Epoch 342/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.5974 - accuracy: 0.5813 - val_loss: 1.4107 - val_accuracy: 0.6610\n",
      "Epoch 343/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.3493 - accuracy: 0.6973 - val_loss: 1.3928 - val_accuracy: 0.6663\n",
      "Epoch 344/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6689 - accuracy: 0.5311 - val_loss: 1.4031 - val_accuracy: 0.6653\n",
      "Epoch 345/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6357 - accuracy: 0.5692 - val_loss: 1.4122 - val_accuracy: 0.6638\n",
      "Epoch 346/350\n",
      "128/128 [==============================] - 38s 303ms/step - loss: 1.5696 - accuracy: 0.5956 - val_loss: 1.4252 - val_accuracy: 0.6362\n",
      "Epoch 347/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 0.8722 - accuracy: 0.9747 - val_loss: 2.1820 - val_accuracy: 0.6199\n",
      "Epoch 348/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.2377 - accuracy: 0.7972 - val_loss: 1.5685 - val_accuracy: 0.6429\n",
      "Epoch 349/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.5858 - accuracy: 0.5654 - val_loss: 1.4137 - val_accuracy: 0.6650\n",
      "Epoch 350/350\n",
      "128/128 [==============================] - 38s 302ms/step - loss: 1.6541 - accuracy: 0.5345 - val_loss: 1.4286 - val_accuracy: 0.6605\n",
      "Сохраняем нейронную сеть\n"
     ]
    }
   ],
   "source": [
    "if ((os.access(file_path, os.F_OK) == False) | (new_model_flag == True)) & (test_model_flag == False) :\n",
    "    print(\"Нейронная сеть Отсутствует\")\n",
    "    # define and fit the final model\n",
    "    print(\"Формируем модель нейросети\")\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.2, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    \n",
    "    #num_logic start\n",
    "    if dataset_type == 'num_logic':\n",
    "        model.add(Dense(\n",
    "            1000,\n",
    "            activation='relu', \n",
    "            kernel_regularizer=regularizers.l2(0.001),\n",
    "            kernel_initializer='random_normal',\n",
    "            bias_initializer='zeros'\n",
    "        ))   \n",
    "        model.add(Dense(\n",
    "            500,\n",
    "            activation='relu', \n",
    "            kernel_regularizer=regularizers.l2(0.001),\n",
    "            kernel_initializer='random_normal',\n",
    "            bias_initializer='zeros'\n",
    "        ))\n",
    "        model.add(Dense(\n",
    "            units=250, \n",
    "            #125,\n",
    "            activation='tanh', \n",
    "            kernel_regularizer=regularizers.l2(0.001),\n",
    "            kernel_initializer='random_normal',\n",
    "            bias_initializer='zeros'\n",
    "        ))\n",
    "        model.add(Dense(\n",
    "            units=150, \n",
    "            #75,\n",
    "            activation='relu', \n",
    "            kernel_regularizer=regularizers.l2(0.001),\n",
    "            kernel_initializer='random_normal',\n",
    "            bias_initializer='zeros'\n",
    "        ))\n",
    "    #num_logic end\n",
    "\n",
    "    model.add(Dense(\n",
    "        3, \n",
    "        kernel_regularizer=regularizers.l2(0.01),\n",
    "        kernel_initializer='random_normal',\n",
    "        bias_initializer='zeros',\n",
    "        activation='softmax'\n",
    "    ))\n",
    "\n",
    "    opt =  keras.optimizers.Adam(clipvalue=1., clipnorm=1., learning_rate = learning_rate,amsgrad = True)\n",
    "    print(\"Компилируем нейронную сеть\")\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t   \n",
    "    \n",
    "    #Обучаем нейронную сеть\n",
    "    print(\"Обучаем нейронную сеть\")\n",
    "    his = model.fit(\n",
    "        training_set, \n",
    "        validation_data=valid_generator, \n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch, \n",
    "        validation_steps = validation_steps, \n",
    "        callbacks=[\n",
    "            #model_checkpoint_ca|llback,\n",
    "            #es\n",
    "            #tensorboard_callback\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if save_model_flag == True:    \n",
    "        #Сохраняем нейронную сеть\n",
    "        print(\"Сохраняем нейронную сеть\")\n",
    "        model.save('./'+neural_path+'/ansamble_'+dataset+'_v1.h5')\n",
    "\n",
    "    #Наблюдаем показатели точности\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Показатели точности обучения нейронной сети, loss MSE')\n",
    "    plt.plot(his.history['loss'], label='loss тренировочной выборки')\n",
    "    plt.plot(his.history['val_loss'], label='loss тестовой выборки')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    losses_results = plt_to_png(plt)\n",
    "    plt.close()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dfab0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказываем результат\n",
      "514/514 [==============================] - 2s 4ms/step\n",
      "4620/4620 [==============================] - 17s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "print(\"Предсказываем результат\")\n",
    "predict_testY = model.predict(testX, verbose = 1)\n",
    "predict_trainY = model.predict(trainX, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2925120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9deab656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразовываем выходные сигналы тренировочной выборки\n",
    "result_predict_trainY = []\n",
    "\n",
    "for predict in predict_trainY:\n",
    "    result_predict_trainY.append(np.argmax(predict))\n",
    "        \n",
    "result_predict_trainY = np.array(result_predict_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1b012b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразовываем выходные сигналы тестовой выборки\n",
    "result_predict_testY = []\n",
    "\n",
    "for predict in predict_testY:\n",
    "    result_predict_testY.append(np.argmax(predict))\n",
    "        \n",
    "result_predict_testY = np.array(result_predict_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f82564f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.set_title('Сигналы тренировочной выборки')\n",
    "\n",
    "# y = trainY#Реальные значения\n",
    "# y1 = result_predict_trainY#Расчетные значения\n",
    "# y1 = y1+3\n",
    "\n",
    "# plt.plot(y, label='Размеченые данные')\n",
    "# plt.plot(y1, label='Расчётные данные нейронной сети')\n",
    "# plt.title('Тренировочная выборка')\n",
    "# plt.legend(loc=\"upper left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a5c0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.set_title('Сигналы тестовой выборки')\n",
    "\n",
    "# y = testY#Реальные значения\n",
    "# y1 = result_predict_testY#Расчетные значения\n",
    "# y1 = y1+3\n",
    "\n",
    "# plt.plot(y, label='Размеченые данные')\n",
    "# plt.plot(y1, label='Расчётные данные нейронной сети')\n",
    "# plt.title('Тестовая выборка')\n",
    "# plt.legend(loc=\"upper left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e5d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b52eeae9",
   "metadata": {},
   "source": [
    "# Расчёт трендов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3520816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тренировочной выборки на основе сигналов по разметке\n",
    "last_train_signal = 2\n",
    "train_trends_origin = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(trainY.shape[0]):\n",
    "    if trainY[i] != last_train_signal and (trainY[i] == 2 or trainY[i] == 0):\n",
    "        last_train_signal = trainY[i]\n",
    "    train_trends_origin.insert(i,last_train_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab2a9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тестовой выборки на основе расчётных сигналов\n",
    "last_test_signal = 2\n",
    "test_trends_origin = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(testY.shape[0]):\n",
    "    if testY[i] != last_test_signal and (testY[i] == 2 or testY[i] == 0):\n",
    "        last_test_signal = testY[i]\n",
    "    test_trends_origin.insert(i,last_test_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "565436f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тренировочной выборки на основе расчётных данных\n",
    "last_train_signal = 2\n",
    "train_trends_predict = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(len(result_predict_trainY)):\n",
    "    if result_predict_trainY[i] != last_train_signal and (result_predict_trainY[i] == 2 or result_predict_trainY[i] == 0):\n",
    "        last_train_signal = result_predict_trainY[i]\n",
    "    train_trends_predict.insert(i,last_train_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb03d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тестовой выборки на основе расчётных сигналов\n",
    "last_test_signal = 2\n",
    "test_trends_predict = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(len(result_predict_testY)):\n",
    "    if result_predict_testY[i] != last_test_signal and (result_predict_testY[i] == 2 or result_predict_testY[i] == 0):\n",
    "        last_test_signal = result_predict_testY[i]\n",
    "    test_trends_predict.insert(i,last_test_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c75e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trends_origin = np.asarray(train_trends_origin).astype(int)\n",
    "test_trends_origin = np.asarray(test_trends_origin).astype(int)\n",
    "train_trends_predict = np.asarray(train_trends_predict).astype(int)\n",
    "test_trends_predict = np.asarray(test_trends_predict).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956abd7",
   "metadata": {},
   "source": [
    "# Расчёт показателей точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8e03ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_score = accuracy_score(train_trends_origin, train_trends_predict)\n",
    "train_roc_auc_score = roc_auc_score(train_trends_origin, train_trends_predict)\n",
    "train_precision_score = precision_score(train_trends_origin, train_trends_predict, pos_label=2)\n",
    "train_recall_score = recall_score(train_trends_origin, train_trends_predict, pos_label=2)\n",
    "train_f1_score = f1_score(train_trends_origin, train_trends_predict, pos_label=2)\n",
    "train_log_loss = log_loss(train_trends_origin, train_trends_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1807abaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "РЕЗУЛЬТАТЫ АНАЛИЗА ТОЧНОСТИ\n",
      "ТРЕНИРОВОЧНАЯ ВЫБОРКА\n",
      "accuracy: 0.5894247616985868\n",
      "roc-auc: 0.588884209626579\n",
      "precision: 0.5843793985005601\n",
      "recall: 0.5616786305908338\n",
      "f1: 0.572804189602016\n",
      "logloss: 14.180922885443248\n"
     ]
    }
   ],
   "source": [
    "#Выводим данные результатов анализа точности\n",
    "print(\"РЕЗУЛЬТАТЫ АНАЛИЗА ТОЧНОСТИ\");\n",
    "\n",
    "print(\"ТРЕНИРОВОЧНАЯ ВЫБОРКА\")\n",
    "print('accuracy:', accuracy_score(train_trends_origin, train_trends_predict))\n",
    "print('roc-auc:', roc_auc_score(train_trends_origin, train_trends_predict))\n",
    "print('precision:', precision_score(train_trends_origin, train_trends_predict, pos_label=2))\n",
    "print('recall:', recall_score(train_trends_origin, train_trends_predict, pos_label=2))\n",
    "print('f1:', f1_score(train_trends_origin, train_trends_predict, pos_label=2))\n",
    "print('logloss:', log_loss(train_trends_origin, train_trends_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c2e0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_score = accuracy_score(test_trends_origin, test_trends_predict)\n",
    "test_roc_auc_score = roc_auc_score(test_trends_origin, test_trends_predict)\n",
    "test_precision_score = precision_score(test_trends_origin, test_trends_predict, pos_label=2)\n",
    "test_recall_score = recall_score(test_trends_origin, test_trends_predict, pos_label=2)\n",
    "test_f1_score = f1_score(test_trends_origin, test_trends_predict, pos_label=2)\n",
    "test_log_loss = log_loss(test_trends_origin, test_trends_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca6551fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ТЕСТОВАЯ ВЫБОРКА\n",
      "accuracy: 0.570437111895775\n",
      "roc-auc: 0.5959170204899599\n",
      "precision: 0.47232882246010904\n",
      "recall: 0.7186539643515673\n",
      "f1: 0.570018281535649\n",
      "logloss: 14.836830886342538\n"
     ]
    }
   ],
   "source": [
    "print(\"ТЕСТОВАЯ ВЫБОРКА\")\n",
    "print('accuracy:', accuracy_score(test_trends_origin, test_trends_predict))\n",
    "print('roc-auc:', roc_auc_score(test_trends_origin, test_trends_predict))\n",
    "print('precision:', precision_score(test_trends_origin, test_trends_predict, pos_label=2))\n",
    "print('recall:', recall_score(test_trends_origin, test_trends_predict, pos_label=2))\n",
    "print('f1:', f1_score(test_trends_origin, test_trends_predict, pos_label=2))\n",
    "print('logloss:', log_loss(test_trends_origin, test_trends_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a7292",
   "metadata": {},
   "source": [
    "# Расчёт доходности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb20566f",
   "metadata": {},
   "source": [
    "# РАСЧЕТ ДОХОДНОСТИ ТРЕНИРОВОЧНОЙ ВЫБОРКИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8dc8e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "РАСЧЕТ ДОХОДНОСТИ ТРЕНИРОВОЧНОЙ ВЫБОРКИ\n"
     ]
    }
   ],
   "source": [
    "print(\"РАСЧЕТ ДОХОДНОСТИ ТРЕНИРОВОЧНОЙ ВЫБОРКИ\")\n",
    "profit_origin_arr = array('f', [])#Массив оригинальной доходности\n",
    "profit_origin_arr_shift = array('f', [])#Массив оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr = array('f', [])#Массив доходности по стандартному отклонению\n",
    "\n",
    "open_pos_flag_origin = False\n",
    "open_pos_flag_calc = False\n",
    "\n",
    "open_price_origin = 0 #Цена открытия позиции\n",
    "open_price_origin_shift = 0 #Цена открытия позиции со смещением на 1 день\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "\n",
    "profit_origin = 0 #Текущая доходность волны\n",
    "profit_origin_shift = 0 #Текущая доходность волны со смещением на 1 день\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "total_profit_origin = 1 #Общая доходность\n",
    "total_profit_origin_shift = 1 #Общая доходность со смещением на 1 день\n",
    "total_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению\n",
    "\n",
    "count_profit_origin = 0 #Номер рассчитанной доходности\n",
    "count_profit_calc_sigma = 0 #Номер рассчитанной доходности по стандартному отклонению\n",
    "\n",
    "one_profit_origin = 1 #Общая доходность при торговле одной акцией\n",
    "one_profit_origin_shift = 1 #Общая доходность со смещением на 1 день при торговле одной акцией\n",
    "one_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению при торговле одной акцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fdc040f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Накопленная доходность по размеченным данным:  [9.2040325e+21]\n",
      "Накопленная доходность по размеченным данным со смещением на 1 день:  [1.1367858e+12]\n",
      "Накопленная доходность по расчётным данным по стандартному отклонению:  [3079040.2]\n",
      "\n",
      "Доходность на одну акцию размеченным данным:  [108.98194]\n",
      "Доходность на одну акцию по размеченным данным со смещением на 1 день:  [85.47331]\n",
      "Доходность на одну акцию по расчётным данным по стандартному отклонению:  [121.49428]\n"
     ]
    }
   ],
   "source": [
    "#Рассчитываем доходность по уровням\n",
    "for i in range(trainX.shape[0]):\n",
    "    #Опредеяем доходность по размеченным данным\n",
    "    if trainY[i] == 2 and open_pos_flag_origin == False:\n",
    "        open_pos_flag_origin = True #Открываем позицию\n",
    "        open_price_origin = train_quotes_close[i] #Фиксируем открытие позиции\n",
    "        try:\n",
    "            open_price_origin_shift = train_quotes_close[i+1] #Фиксируем открытие позиции\n",
    "        except:\n",
    "            open_price_origin_shift = train_quotes_close[i] #Фиксируем открытие позиции\n",
    "    if trainY[i] == 0 and open_pos_flag_origin == True:\n",
    "        open_pos_flag_origin = False #Закрываем позицию\n",
    "        profit_origin = train_quotes_close[i]/open_price_origin #Фиксируем прибыль\n",
    "        one_profit_origin = one_profit_origin + (profit_origin-1) #Вычисляем доходность на одну акцию\n",
    "        try:\n",
    "            profit_origin_shift = train_quotes_close[i+1]/open_price_origin_shift #Фиксируем прибыль со смещением на 1 день\n",
    "        except:\n",
    "            profit_origin_shift = train_quotes_close[i]/open_price_origin_shift\n",
    "        total_profit_origin = total_profit_origin * profit_origin #Рассчитываем общую доходность\n",
    "        one_profit_origin_shift = one_profit_origin_shift + (profit_origin_shift-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_origin_shift = total_profit_origin_shift * profit_origin_shift #Рассчитываем общую доходность со смещением на 1 день\n",
    "        profit_origin_arr.insert(count_profit_origin, profit_origin) #Добавляем прибыль в массив\n",
    "        profit_origin_arr_shift.insert(count_profit_origin, profit_origin_shift) #Добавляем прибыль со смещением на 1 день в массив\n",
    "        count_profit_origin = count_profit_origin+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "#Обнуляем данные\n",
    "open_pos_flag_calc = False\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "#Рассчитываем доходность тренировочной выборки\n",
    "for i in range(trainX.shape[0]):\n",
    "    #Опредеяем доходность по рассчетным данным\n",
    "    if result_predict_trainY[i] == 2 and open_pos_flag_calc == False:\n",
    "        open_pos_flag_calc = True #Открываем позицию\n",
    "        open_price_calc = train_quotes_close[i] #Фиксируем открытие позиции\n",
    "    if result_predict_trainY[i] == 0 and open_pos_flag_calc == True:\n",
    "        open_pos_flag_calc = False #Закрываем позицию\n",
    "        profit_calc = train_quotes_close[i]/open_price_calc #Фиксируем прибыль\n",
    "        one_profit_calc_sigma = one_profit_calc_sigma + (profit_calc-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_calc_sigma = total_profit_calc_sigma * profit_calc #Рассчитываем общую доходность\n",
    "        profit_calc_sigma_arr.insert(count_profit_calc_sigma, profit_calc) #Добавляем прибыль в массив\n",
    "        count_profit_calc_sigma = count_profit_calc_sigma+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "\n",
    "result_profit_origin_arr = np.asarray(profit_origin_arr)\n",
    "result_profit_origin_arr_shift = np.asarray(profit_origin_arr_shift)\n",
    "result_profit_calc_sigma_arr = np.asarray(profit_calc_sigma_arr)\n",
    "\n",
    "print(\"Накопленная доходность по размеченным данным: \", total_profit_origin)\n",
    "print(\"Накопленная доходность по размеченным данным со смещением на 1 день: \", total_profit_origin_shift)\n",
    "print(\"Накопленная доходность по расчётным данным по стандартному отклонению: \", total_profit_calc_sigma)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Доходность на одну акцию размеченным данным: \", one_profit_origin)\n",
    "print(\"Доходность на одну акцию по размеченным данным со смещением на 1 день: \", one_profit_origin_shift)\n",
    "print(\"Доходность на одну акцию по расчётным данным по стандартному отклонению: \", one_profit_calc_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72048764",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Доходность трейдов тренировочной выборки')\n",
    "\n",
    "ax.hlines(1, 0, count_profit_origin)\n",
    "ax.hlines(0.5, 0, count_profit_origin)\n",
    "ax.hlines(0, 0, count_profit_calc_sigma)\n",
    "\n",
    "y_calc_profit_origin = result_profit_origin_arr\n",
    "y_calc_profit_origin_shift = result_profit_origin_arr_shift - 0.5\n",
    "y_calc_profit_sigma = result_profit_calc_sigma_arr - 1\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением на 1 день')\n",
    "plt.plot(y_calc_profit_sigma, label='Рассчётные данные данные')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fd46c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_origin_arr_summ = array('f', [])#Массив накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ = array('f', [])#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ = array('f', [])#Массив накопленной доходности по стандартному отклонению\n",
    "\n",
    "profit_origin_arr_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ_show = array('f', [])#Массив смещённой накопленной доходности по стандартному отклонению\n",
    "\n",
    "last_profit_origin = 1\n",
    "last_profit_origin_shift = 1\n",
    "last_profit_calc_sigma = 1\n",
    "\n",
    "shift_origin = 0\n",
    "shift_origin_shift = -1\n",
    "shift_calc_sigma = -2\n",
    "\n",
    "for i in range(len(profit_origin_arr)):\n",
    "    profit_origin_arr_summ_show.insert(i,last_profit_origin*profit_origin_arr[i]-shift_origin)\n",
    "    profit_origin_arr_summ.insert(i,last_profit_origin*profit_origin_arr[i])\n",
    "    last_profit_origin = last_profit_origin*profit_origin_arr[i]\n",
    "\t\n",
    "for i in range(len(profit_origin_arr_shift)):\n",
    "    profit_origin_arr_shift_summ_show.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i]-shift_origin_shift)\n",
    "    profit_origin_arr_shift_summ.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i])\n",
    "    last_profit_origin_shift = last_profit_origin_shift*profit_origin_arr_shift[i]\n",
    "\n",
    "for i in range(len(profit_calc_sigma_arr)):\n",
    "    profit_calc_sigma_arr_summ_show.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i]-shift_calc_sigma)\n",
    "    profit_calc_sigma_arr_summ.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i])\n",
    "    last_profit_calc_sigma = last_profit_calc_sigma*profit_calc_sigma_arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b0f8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Накопленная доходность тренировочной выборки')\n",
    "\n",
    "y_calc_profit_origin = profit_origin_arr_summ_show\n",
    "y_calc_profit_origin_shift = profit_origin_arr_shift_summ_show\n",
    "y_calc_profit_sigma = profit_calc_sigma_arr_summ_show\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением')\n",
    "plt.plot(y_calc_profit_sigma, label='Рассчётные данные')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ea2116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_profit_origin_arr = profit_origin_arr#Массив оригинальной доходности\n",
    "train_profit_origin_arr_shift = profit_origin_arr_shift#Массив оригинальной доходности со смещением на 1 день\n",
    "train_profit_calc_sigma_arr = profit_calc_sigma_arr#Массив доходности по стандартному отклонению\n",
    "\n",
    "train_profit_origin_arr_summ = profit_origin_arr_summ#Массив накопленной оригинальной доходности\n",
    "train_profit_origin_arr_shift_summ = profit_origin_arr_shift_summ#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "train_profit_calc_sigma_arr_summ = profit_calc_sigma_arr_summ#Массив накопленной доходности по стандартному отклонению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab4966",
   "metadata": {},
   "source": [
    "# Тестовая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a31cbf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "РАСЧЕТ ДОХОДНОСТИ ТЕСТОВОЙ ВЫБОРКИ\n",
      "Накопленная доходность по размеченным данным:  [9.74166e+09]\n",
      "Накопленная доходность по размеченным данным со смещением на 1 день:  [8.128909e+08]\n",
      "Накопленная доходность по расчётным данным:  [2.2186478e+09]\n",
      "\n",
      "Доходность на одну акцию размеченным данным:  [153672.81]\n",
      "Доходность на одну акцию по размеченным данным со смещением на 1 день:  [153345.72]\n",
      "Доходность на одну акцию по расчётным данным:  [150971.11]\n"
     ]
    }
   ],
   "source": [
    "\t#РАСЧЕТ ДОХОДНОСТИ ТЕСТОВОЙ ВЫБОРКИ\n",
    "print(\"\")\n",
    "print(\"РАСЧЕТ ДОХОДНОСТИ ТЕСТОВОЙ ВЫБОРКИ\")\n",
    "profit_origin_arr = array('f', [])#Массив оригинальной доходности\n",
    "profit_origin_arr_shift = array('f', [])#Массив оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr = array('f', [])#Массив доходности по стандартному отклонению\n",
    "\n",
    "open_pos_flag_origin = False\n",
    "open_pos_flag_calc = False\n",
    "\n",
    "open_price_origin = 0 #Цена открытия позиции\n",
    "open_price_origin_shift = 0 #Цена открытия позиции со смещением на 1 день\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "\n",
    "profit_origin = 0 #Текущая доходность волны\n",
    "profit_origin_shift = 0 #Текущая доходность волны со смещением на 1 день\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "total_profit_origin = 1 #Общая доходность\n",
    "total_profit_origin_shift = 1 #Общая доходность со смещением на 1 день\n",
    "total_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению\n",
    "\n",
    "count_profit_origin = 0 #Номер рассчитанной доходности\n",
    "count_profit_calc_sigma = 0 #Номер рассчитанной доходности по стандартному отклонению\n",
    "\n",
    "one_profit_origin = 1 #Общая доходность при торговле одной акцией\n",
    "one_profit_origin_shift = 1 #Общая доходность со смещением на 1 день при торговле одной акцией\n",
    "one_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению при торговле одной акцией\n",
    "\n",
    "#Рассчитываем доходность по уровням\n",
    "for i in range(testX.shape[0]):\n",
    "    #Опредеяем доходность по размеченным данным\n",
    "    if testY[i] == 2 and open_pos_flag_origin == False:\n",
    "        open_pos_flag_origin = True #Открываем позицию\n",
    "        open_price_origin = test_quotes_close[i] #Фиксируем открытие позиции\n",
    "        open_price_origin_shift = test_quotes_close[i+1] #Фиксируем открытие позиции\n",
    "    if testY[i] == 0 and open_pos_flag_origin == True:\n",
    "        open_pos_flag_origin = False #Закрываем позицию\n",
    "        profit_origin = test_quotes_close[i]/open_price_origin #Фиксируем прибыль\n",
    "        one_profit_origin = one_profit_origin + (profit_origin-1) #Вычисляем доходность на одну акцию\n",
    "        profit_origin_shift = test_quotes_close[i+1]/open_price_origin_shift #Фиксируем прибыль со смещением на 1 день\n",
    "        total_profit_origin = total_profit_origin * profit_origin #Рассчитываем общую доходность\n",
    "        one_profit_origin_shift = one_profit_origin_shift + (profit_origin_shift-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_origin_shift = total_profit_origin_shift * profit_origin_shift #Рассчитываем общую доходность со смещением на 1 день\n",
    "        profit_origin_arr.insert(count_profit_origin, profit_origin) #Добавляем прибыль в массив\n",
    "        profit_origin_arr_shift.insert(count_profit_origin, profit_origin_shift) #Добавляем прибыль со смещением на 1 день в массив\n",
    "        count_profit_origin = count_profit_origin+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "#Обнуляем данные\n",
    "open_pos_flag_calc = False\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "#Рассчитываем доходность тренировочной выборки\n",
    "for i in range(testX.shape[0]):\n",
    "    #Опредеяем доходность по рассчетным данным\n",
    "    if result_predict_testY[i] == 2 and open_pos_flag_calc == False:\n",
    "        open_pos_flag_calc = True #Открываем позицию\n",
    "        open_price_calc = test_quotes_close[i] #Фиксируем открытие позиции\n",
    "    if result_predict_testY[i] == 0 and open_pos_flag_calc == True:\n",
    "        open_pos_flag_calc = False #Закрываем позицию\n",
    "        profit_calc = test_quotes_close[i]/open_price_calc #Фиксируем прибыль\n",
    "        one_profit_calc_sigma = one_profit_calc_sigma + (profit_calc-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_calc_sigma = total_profit_calc_sigma * profit_calc #Рассчитываем общую доходность\n",
    "        profit_calc_sigma_arr.insert(count_profit_calc_sigma, profit_calc) #Добавляем прибыль в массив\n",
    "        count_profit_calc_sigma = count_profit_calc_sigma+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "\n",
    "result_profit_origin_arr = np.asarray(profit_origin_arr)\n",
    "result_profit_origin_arr_shift = np.asarray(profit_origin_arr_shift)\n",
    "result_profit_calc_sigma_arr = np.asarray(profit_calc_sigma_arr)\n",
    "\n",
    "print(\"Накопленная доходность по размеченным данным: \", total_profit_origin)\n",
    "print(\"Накопленная доходность по размеченным данным со смещением на 1 день: \", total_profit_origin_shift)\n",
    "print(\"Накопленная доходность по расчётным данным: \", total_profit_calc_sigma)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Доходность на одну акцию размеченным данным: \", one_profit_origin)\n",
    "print(\"Доходность на одну акцию по размеченным данным со смещением на 1 день: \", one_profit_origin_shift)\n",
    "print(\"Доходность на одну акцию по расчётным данным: \", one_profit_calc_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ac1ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Доходность трейдов тестовой выборки')\n",
    "\n",
    "ax.hlines(1, 0, count_profit_origin)\n",
    "ax.hlines(0.5, 0, count_profit_origin)\n",
    "ax.hlines(0, 0, count_profit_calc_sigma)\n",
    "\n",
    "y_calc_profit_origin = result_profit_origin_arr\n",
    "y_calc_profit_origin_shift = result_profit_origin_arr_shift - 0.5\n",
    "y_calc_profit_sigma = result_profit_calc_sigma_arr - 1\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением на 1 день')\n",
    "plt.plot(y_calc_profit_sigma, label='Расчётные данные')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4212c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_origin_arr_summ = array('f', [])#Массив накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ = array('f', [])#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ = array('f', [])#Массив накопленной доходности по стандартному отклонению\n",
    "\n",
    "profit_origin_arr_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ_show = array('f', [])#Массив смещённой накопленной доходности по стандартному отклонению\n",
    "\n",
    "last_profit_origin = 1\n",
    "last_profit_origin_shift = 1\n",
    "last_profit_calc_sigma = 1\n",
    "\n",
    "shift_origin = 0\n",
    "shift_origin_shift = -1\n",
    "shift_calc_sigma = -2\n",
    "\n",
    "for i in range(len(profit_origin_arr)):\n",
    "    profit_origin_arr_summ_show.insert(i,last_profit_origin*profit_origin_arr[i]-shift_origin)\n",
    "    profit_origin_arr_summ.insert(i,last_profit_origin*profit_origin_arr[i])\n",
    "    last_profit_origin = last_profit_origin*profit_origin_arr[i]\n",
    "\t\n",
    "for i in range(len(profit_origin_arr_shift)):\n",
    "    profit_origin_arr_shift_summ_show.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i]-shift_origin_shift)\n",
    "    profit_origin_arr_shift_summ.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i])\n",
    "    last_profit_origin_shift = last_profit_origin_shift*profit_origin_arr_shift[i]\n",
    "\n",
    "for i in range(len(profit_calc_sigma_arr)):\n",
    "    profit_calc_sigma_arr_summ_show.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i]-shift_calc_sigma)\n",
    "    profit_calc_sigma_arr_summ.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i])\n",
    "    last_profit_calc_sigma = last_profit_calc_sigma*profit_calc_sigma_arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "079e6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Накопленная доходность тестовой выборки')\n",
    "\n",
    "y_calc_profit_origin = profit_origin_arr_summ_show\n",
    "y_calc_profit_origin_shift = profit_origin_arr_shift_summ_show\n",
    "y_calc_profit_sigma = profit_calc_sigma_arr_summ_show\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением на 1 день')\n",
    "plt.plot(y_calc_profit_sigma, label='Рассчётные сигналы')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "test_profit_origin_arr = profit_origin_arr#Массив оригинальной доходности\n",
    "test_profit_origin_arr_shift = profit_origin_arr_shift#Массив оригинальной доходности со смещением на 1 день\n",
    "test_profit_calc_sigma_arr = profit_calc_sigma_arr#Массив доходности по стандартному отклонению\n",
    "\n",
    "test_profit_origin_arr_summ = profit_origin_arr_summ#Массив накопленной оригинальной доходности\n",
    "test_profit_origin_arr_shift_summ = profit_origin_arr_shift_summ#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "test_profit_calc_sigma_arr_summ = profit_calc_sigma_arr_summ#Массив накопленной доходности по стандартному отклонению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457e9b12",
   "metadata": {},
   "source": [
    "# РАСЧЕТ РИСКОВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0db8351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "РАСЧЕТ РИСКОВ\n",
      "ТРЕНИРОВОЧНАЯ ВЫБОРКА\n",
      "Дисперсия по размеченным данным:  inf\n",
      "Дисперсия по размеченным данным со смещением:  2.4811296e+22\n",
      "Дисперсия по расчётным данным:  972141560000.0\n",
      "Коэффициент Шарпа по размеченным данным:  0.0\n",
      "Коэффициент Шарпа по размеченным данным со смещением:  721.6957435279093\n",
      "Коэффициент Шарпа по расчётным данным:  312.28548809084657\n",
      "ТЕСТОВАЯ ВЫБОРКА\n",
      "Дисперсия по размеченным данным:  5.412509e+18\n",
      "Дисперсия по размеченным данным со смещением:  4.3585367e+16\n",
      "Дисперсия по расчётным данным:  3.9078997e+17\n",
      "Коэффициент Шарпа по размеченным данным:  418.729718872813\n",
      "Коэффициент Шарпа по размеченным данным со смещением:  389.36947187588277\n",
      "Коэффициент Шарпа по расчётным данным:  354.90842775631876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:236: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    }
   ],
   "source": [
    "print(\"РАСЧЕТ РИСКОВ\")\n",
    "\n",
    "#ТРЕНИРОВОЧНАЯ ВЫБОРКА\n",
    "print(\"ТРЕНИРОВОЧНАЯ ВЫБОРКА\")\n",
    "\n",
    "#Дисперсия портфеля\n",
    "\n",
    "#Дисперсия по размеченным данным\n",
    "print(\"Дисперсия по размеченным данным: \", np.var(train_profit_origin_arr_summ))\n",
    "\n",
    "#Дисперсия по размеченным данным со смещением\n",
    "print(\"Дисперсия по размеченным данным со смещением: \", np.var(train_profit_origin_arr_shift_summ))\n",
    "\n",
    "#Дисперсия по расчётным данным\n",
    "print(\"Дисперсия по расчётным данным: \", np.var(train_profit_calc_sigma_arr_summ))\n",
    "\n",
    "#Коэффициент Шарпа\n",
    "R = 5#Безрисковая ставка\n",
    "#Коэффициент Шарпа по размеченным данным\n",
    "print(\"Коэффициент Шарпа по размеченным данным: \", ((train_profit_origin_arr_summ[len(train_profit_origin_arr_summ)-1]-1)*100-R)/sqrt(np.var(train_profit_origin_arr_summ)))\n",
    "\n",
    "#Коэффициент Шарпа по размеченным данным со смещением\n",
    "print(\"Коэффициент Шарпа по размеченным данным со смещением: \", ((train_profit_origin_arr_shift_summ[len(train_profit_origin_arr_shift_summ)-1]-1)*100-R)/sqrt(np.var(train_profit_origin_arr_shift_summ)))\n",
    "\n",
    "sharp = 0\t\t\n",
    "if train_profit_calc_sigma_arr_summ != 0:\n",
    "    sharp = ((train_profit_calc_sigma_arr_summ[len(train_profit_calc_sigma_arr_summ)-1]-1)*100-R)/sqrt(np.var(train_profit_calc_sigma_arr_summ))\n",
    "\n",
    "#Коэффициент Шарпа по расчётным данным\n",
    "print(\"Коэффициент Шарпа по расчётным данным: \", sharp)\n",
    "\n",
    "#ТЕСТОВАЯ ВЫБОРКА\n",
    "print(\"ТЕСТОВАЯ ВЫБОРКА\")\n",
    "#Дисперсия портфеля\n",
    "\n",
    "#Дисперсия по размеченным данным\n",
    "print(\"Дисперсия по размеченным данным: \", np.var(test_profit_origin_arr_summ))\n",
    "\n",
    "#Дисперсия по размеченным данным со смещением\n",
    "print(\"Дисперсия по размеченным данным со смещением: \", np.var(test_profit_origin_arr_shift_summ))\n",
    "\n",
    "#Дисперсия по расчётным данным\n",
    "print(\"Дисперсия по расчётным данным: \", np.var(test_profit_calc_sigma_arr_summ))\n",
    "\n",
    "#Коэффициент Шарпа\n",
    "R = 5#Безрисковая ставка\n",
    "\t\t#Коэффициент Шарпа по размеченным данным\n",
    "sharp = 0\t\t\n",
    "if sqrt(np.var(test_profit_origin_arr_summ)) != 0:\n",
    "    sharp = ((test_profit_origin_arr_summ[len(test_profit_origin_arr_summ)-1]-1)*100-R)/sqrt(np.var(test_profit_origin_arr_summ))\n",
    "print(\"Коэффициент Шарпа по размеченным данным: \", sharp)\n",
    "\n",
    "#Коэффициент Шарпа по размеченным данным со смещением\n",
    "sharp = 0\t\t\n",
    "if sqrt(np.var(test_profit_origin_arr_shift_summ)) != 0:\n",
    "    sharp = ((test_profit_origin_arr_shift_summ[len(test_profit_origin_arr_shift_summ)-1]-1)*100-R)/sqrt(np.var(test_profit_origin_arr_shift_summ))\n",
    "\n",
    "#Коэффициент Шарпа по расчётным данным\n",
    "print(\"Коэффициент Шарпа по размеченным данным со смещением: \", sharp)\n",
    "\n",
    "sharp = 0\n",
    "if sqrt(np.var(test_profit_calc_sigma_arr_summ)) != 0:\n",
    "    sharp = ((test_profit_calc_sigma_arr_summ[len(test_profit_calc_sigma_arr_summ)-1]-1)*100-R)/sqrt(np.var(test_profit_calc_sigma_arr_summ))\n",
    "\n",
    "#Коэффициент Шарпа по расчётным данным\n",
    "print(\"Коэффициент Шарпа по расчётным данным: \", sharp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf22ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb16c567",
   "metadata": {},
   "source": [
    "# Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2c071052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Соединение с БД\n",
    "def connect():\n",
    "    return psycopg2.connect(\n",
    "        host=global_config.db_host,\n",
    "        database=global_config.db_database,\n",
    "        user=global_config.db_user,\n",
    "        password=global_config.db_password\n",
    "    )\n",
    "conn = connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "366a4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conn.closed == 1:\n",
    "    conn = connect()\n",
    "#Проверяем наличие записи\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM public.edu_neural_results WHERE task_id  = %s;\", (task_id,))\n",
    "results = cur.fetchall()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cee32321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обновляем результаты\n"
     ]
    }
   ],
   "source": [
    "if conn.closed == 1:\n",
    "    conn = connect()\n",
    "cur = conn.cursor()\n",
    "try:\n",
    "    if len(results) == 0:\n",
    "        print(\"Записываем результаты\")\n",
    "        #Записи о результатах в БД нет, записываем новый результат\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO public.edu_neural_results \n",
    "            (\n",
    "                task_id, \n",
    "                losses_results, \n",
    "                train_accuracy_score, \n",
    "                train_roc_auc_score, \n",
    "                train_precision_score, \n",
    "                train_recall_score, \n",
    "                train_f1_score, \n",
    "                train_log_loss,\n",
    "                test_accuracy_score, \n",
    "                test_roc_auc_score, \n",
    "                test_precision_score, \n",
    "                test_recall_score, \n",
    "                test_f1_score, \n",
    "                test_log_loss\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "            \"\"\",\n",
    "            (\n",
    "                task_id, \n",
    "                losses_results, \n",
    "                train_accuracy_score, \n",
    "                train_roc_auc_score, \n",
    "                train_precision_score, \n",
    "                train_recall_score, \n",
    "                train_f1_score, \n",
    "                train_log_loss,\n",
    "                test_accuracy_score, \n",
    "                test_roc_auc_score, \n",
    "                test_precision_score, \n",
    "                test_recall_score, \n",
    "                test_f1_score, \n",
    "                test_log_loss\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        #Обновляем запись\n",
    "        print(\"Обновляем результаты\")\n",
    "        sql = \"\"\" UPDATE public.edu_neural_results\n",
    "                    SET \n",
    "                    losses_results = %s, \n",
    "                    train_accuracy_score = %s, \n",
    "                    train_roc_auc_score = %s, \n",
    "                    train_precision_score = %s, \n",
    "                    train_recall_score = %s, \n",
    "                    train_f1_score = %s, \n",
    "                    train_log_loss = %s,\n",
    "                    test_accuracy_score = %s, \n",
    "                    test_roc_auc_score = %s, \n",
    "                    test_precision_score = %s, \n",
    "                    test_recall_score = %s, \n",
    "                    test_f1_score = %s, \n",
    "                    test_log_loss = %s\n",
    "                    WHERE task_id = %s\"\"\"\n",
    "        cur.execute(sql, (\n",
    "                losses_results, \n",
    "                train_accuracy_score, \n",
    "                train_roc_auc_score, \n",
    "                train_precision_score, \n",
    "                train_recall_score, \n",
    "                train_f1_score, \n",
    "                train_log_loss,\n",
    "                test_accuracy_score, \n",
    "                test_roc_auc_score, \n",
    "                test_precision_score, \n",
    "                test_recall_score, \n",
    "                test_f1_score, \n",
    "                test_log_loss,\n",
    "                task_id\n",
    "            ))\n",
    "except Exception as e:\n",
    "    print(\"Ошибка записи результатов в БД: \", e)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47378885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обновляем данные по задаче\n",
    "if conn.closed == 1:\n",
    "    conn = connect()\n",
    "cur = conn.cursor()\n",
    "\n",
    "sql = \"\"\" UPDATE data_markup_results\n",
    "            SET task_status = %s\n",
    "            WHERE id = %s\"\"\"\n",
    "try:\n",
    "    cur.execute(sql, ('done', task_id))\n",
    "except Exception as e:\n",
    "    print(\"Ошибка записи информации о закрытии задачи в БД: \", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
